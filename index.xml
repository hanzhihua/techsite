<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>一个码农 工作点滴</title>
    <link>https://hanzhihua.cn/</link>
    <description>Recent content on 一个码农 工作点滴</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>All rights reserved - 2019 &lt;a href=&#34;http://www.beian.miit.gov.cn&#34;&gt;沪ICP备19026538号&lt;/a&gt; </copyright>
    <lastBuildDate>Thu, 30 Jan 2020 10:36:14 +0800</lastBuildDate>
    
        <atom:link href="https://hanzhihua.cn/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>大数据平台DAG应用</title>
      <link>https://hanzhihua.cn/post/dag_2/</link>
      <pubDate>Thu, 30 Jan 2020 10:36:14 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/dag_2/</guid>
      
        <description>

&lt;h2 id=&#34;dag基本概念&#34;&gt;DAG基本概念&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;DAG：（Directed acyclic graph）有向无环图&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;首先它是一个图，非线性结构，多对多，由两个集合节点（Vertex)和边(Edge)组成&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;有向图 &amp;amp;&amp;amp; 无向图&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;区别Edge是不是有方向，DAG是有向图，是有方向的&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;无向完全图 &amp;amp;&amp;amp; 有向完全图&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;对于无向图拥有 n(n-1)/2的Edge,对于有向图拥有n(n-1)的Edge&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;顶点的度数

&lt;ul&gt;
&lt;li&gt;对于无向图，顶点的度表示以该顶点作为一个端点的边的数目&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;对于有向图，区分入度和出度，入度表示以该顶点为终点的入边数目，出度是以该顶点为起点的出边数目，该顶点的度等于其入度和出度之和&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;连通图&amp;amp;&amp;amp;非连通图

&lt;ul&gt;
&lt;li&gt;根据顶点是否连通来分别&lt;/li&gt;
&lt;li&gt;大数据平台DAG一般是非连通图&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;存储结构

&lt;ul&gt;
&lt;li&gt;邻接矩阵，行、列表明入度和出度的情况&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;邻接表，对于图中每个顶点，把所有邻接于该顶点的顶点链成一个单链表&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;图的遍历包括BFS、DFS

&lt;ul&gt;
&lt;li&gt;DFS 深度优先搜索遍历 （采用邻接矩阵存储，则时间复杂度为O(n2)；当采用邻接表时时间复杂度为O(n+e)。）&lt;/li&gt;
&lt;li&gt;BFS 广度优先搜索遍历  (采用邻接矩阵存储，则时间复杂度为O(n2)；当采用邻接表时时间复杂度为O(n+e)。）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;拓扑排序

&lt;ul&gt;
&lt;li&gt;只针对DAG，需要满足下面两个条件&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;每个顶点出现且只出现一次&lt;/li&gt;
&lt;li&gt;若存在一条从顶点 A 到顶点 B 的路径，那么在序列中顶点 A 出现在顶点 B 的前面&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;通常，一个有向无环图满足上述两个条件可以有一个或多个拓扑排序序列&lt;/strong&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;大数据平台的应用&#34;&gt;大数据平台的应用&lt;/h2&gt;

&lt;h3 id=&#34;调度系统中的应用&#34;&gt;调度系统中的应用&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;调度系统中的任务就是一个典型DAG&lt;/li&gt;
&lt;li&gt;判断DAG是否存在环状&lt;/li&gt;
&lt;li&gt;判读两个任务是否存在依赖关系&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;实现方式&#34;&gt;实现方式&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;采用邻接表表方式存储&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;伪代码&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final Map nodesMap = new HashMap&amp;lt;&amp;gt;(); //顶点

private final Map edgesMap = new HashMap&amp;lt;&amp;gt;(); //出度关系

private final Map reverseEdgesMap = new HashMap&amp;lt;&amp;gt;(); //入度关系
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;使用DFS或者BFS判断是否有环，都比较方便&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>OLAP系统设计草案</title>
      <link>https://hanzhihua.cn/post/olap_1/</link>
      <pubDate>Tue, 31 Dec 2019 10:56:08 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/olap_1/</guid>
      
        <description>

&lt;h2 id=&#34;目标&#34;&gt;目标&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;主要针对用户侧&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据录入时延 &amp;lt; 1h

&lt;ul&gt;
&lt;li&gt;支持实时录入&lt;/li&gt;
&lt;li&gt;支持离线录入&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;99% 查询时延 &amp;lt; 5s&lt;/li&gt;
&lt;li&gt;不支持在线业务&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;设计原则&#34;&gt;设计原则&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;复用已有框架

&lt;ul&gt;
&lt;li&gt;数据的可靠性，依靠hdfs来实现&lt;/li&gt;
&lt;li&gt;数据的录入，依靠Spark、MR任务&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;开源OLAP引擎集群管理，可灵活的适配不同的开源OLAP引擎

&lt;ul&gt;
&lt;li&gt;大数据平台 ，作为分布式一种应用，它具有以下特点&lt;/li&gt;
&lt;li&gt;数据量大，需要大量的机器&lt;/li&gt;
&lt;li&gt;算法和存储结构对性能起到决定性的作用&lt;/li&gt;
&lt;li&gt;没有银弹，每个开源的计算引擎都有它的适用范围&lt;/li&gt;
&lt;li&gt;整体技术架构中，多几层RPC调用设计是可行的，性能损耗可忽略&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;数据源接入OLAP系统工程化，选择最优的计算引擎，并提供SLA标准&lt;/li&gt;
&lt;li&gt;用户不感知具体的技术引擎，切换计算引擎用户无感知&lt;/li&gt;
&lt;li&gt;教育用户，并提供专家系统，修改请求语句&lt;/li&gt;
&lt;li&gt;引擎适用范畴

&lt;ul&gt;
&lt;li&gt;Kylin 适用维度有限，对延时敏感&lt;/li&gt;
&lt;li&gt;Druid 适用维度相对多，对延时不是特别敏感&lt;/li&gt;
&lt;li&gt;Presto ADhoc查询，需要控制并发度&lt;/li&gt;
&lt;li&gt;Clickhouse：与Druid相似&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;架构图-运行时图-逻辑图&#34;&gt;架构图（运行时图&amp;amp;&amp;amp;逻辑图）&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;网关层：不感知引擎，有状态，分集群，一个集群多组网关层&lt;/li&gt;
&lt;li&gt;引擎适配层：为特定引擎服务，有状态，解析请求，优化，合并结果，同时也是引擎管理的执行者，接受管理系统指派工作（视图优化、冷热数据管理）&lt;/li&gt;
&lt;li&gt;SDK: 寻址，维护sessionID，有状态，发送请求、状态接收&lt;/li&gt;
&lt;li&gt;管理系统：所有管理工作，管理集群、引擎、网关、引擎适配层，包括路由、数据迁移等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;

&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/Snip20191231_17.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/Snip20191231_17.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;



&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/Snip20191231_18.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/Snip20191231_18.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>路由不均衡问题</title>
      <link>https://hanzhihua.cn/post/cs_6/</link>
      <pubDate>Sat, 14 Dec 2019 15:55:50 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/cs_6/</guid>
      
        <description>

&lt;p&gt;最近上线一个版本的调度系统，偶尔出现访问hiveserver2超时&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;调度系统访问hiveserver2偶尔出现超时现象&lt;/li&gt;
&lt;li&gt;查看监控，发现hiveserver2集群访问很不均匀&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;调度系统访问hiveserver2路由是采用smart client方式
查看代码&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;for(String hiveserver2 :hiveserver2s){
if(!判断是否可用(hiveserver2)){
   logger.warn(&amp;quot;ignore invalidate hive serer:{}&amp;quot;,hiveserver2);
   continue;
}
try{
访问（hiveserver2);
}cache(服务不可用异常 e){
   //该hiveserver2置为不可用
}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;问题找到了 就是hiveserver2s 的顺序是固定的，这样造成了一直访问一台服务器，直到它不能在工作了，再换到下一台&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;改善措施&#34;&gt;改善措施&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;把hiveserver2s随机打散&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Collections.shuffle(hiveserver2);
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Hudi 原理分析</title>
      <link>https://hanzhihua.cn/post/hudi_1/</link>
      <pubDate>Wed, 11 Dec 2019 12:28:55 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/hudi_1/</guid>
      
        <description>

&lt;h2 id=&#34;什么是hudi&#34;&gt;什么是Hudi&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;一个spark 库&lt;/li&gt;
&lt;li&gt;大数据更新解决方案

&lt;ul&gt;
&lt;li&gt;大数据中没有传统意义的更新，只有append和重写，(&lt;em&gt;Hudi就是采用重写方式&lt;/em&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;使用Hudi的优点&lt;/strong&gt;：

&lt;ul&gt;
&lt;li&gt;使用Bloomfilter机制+二次查找，可快速确定记录是更新还是新增&lt;/li&gt;
&lt;li&gt;更新范围小，是文件级别，不是表级别&lt;/li&gt;
&lt;li&gt;文件大小与hdfs的Blocksize保持一致&lt;/li&gt;
&lt;li&gt;数据文件使用parquet格式，充分利用列存的优势（*dremal论文实现*）&lt;/li&gt;
&lt;li&gt;提供了可扩展的大数据更新框架&lt;/li&gt;
&lt;li&gt;并发度由spark控制&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;一些概念&#34;&gt;一些概念&lt;/h2&gt;

&lt;h3 id=&#34;存储模型&#34;&gt;存储模型&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;COW (CopyOnWrite)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;使用数据文件（parquet）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;输入的格式是Avro，直接写入parquet数据文件中&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;MOR (MergeOnRead)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;使用数据文件（parquet）和日志文件（avro格式）&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;新增记录写入先写入日志文件中，更新数据直接写入数据文件&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;后台异步日志文件转成数据文件&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;可以显示调用compact ，同步写入parquet数据文件&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;parquet数据文件格式&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;文件上面部分是数据&lt;/li&gt;
&lt;li&gt;文件底部是bloomfilter（默认）&lt;/li&gt;
&lt;li&gt;如果采用hbase，会有索引文件&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;h6 id=&#34;对象模型&#34;&gt;对象模型&lt;/h6&gt;

&lt;ul&gt;
&lt;li&gt;HoodieRecord (包括下面两个模型和业务对象（avro格式）)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;HoodieKey （包括业务主键，业务分区）&lt;/li&gt;
&lt;li&gt;HoodieRecordLocation （文件id，和时间）&lt;/li&gt;
&lt;li&gt;时间轴&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;可查询任何历史快照、增量数据&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;写流程&#34;&gt;写流程&lt;/h2&gt;

&lt;h3 id=&#34;cow玩法&#34;&gt;Cow玩法&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;生成JavaRDD，里面包括所有的需要新增或者更新的记录&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;**这里面的记录只有业务主键，分区，数据，没有文件ID **&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;根据Bloomfilter功能和Partitioner功能把文件ID补全&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果记录是更新，则文件ID就是原来的文件ID，如果是新增记录，文件ID是新建立的&lt;/li&gt;
&lt;li&gt;对所有需要更新的文件，合并原有记录和更新记录重新生成一个文件（FileId相同）&lt;/li&gt;
&lt;li&gt;对所有新增的记录，生成一个新的文件&lt;/li&gt;
&lt;li&gt;Partitioner的功能保证文件的大小跟hdfs的blocksize保持一致&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;mor玩法&#34;&gt;MOR玩法&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;玩法与Cow类似，不同的地方是，新增记录先写入日志文件（avro格式）&lt;/li&gt;
&lt;li&gt;在概念中已描述&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;读流程&#34;&gt;读流程&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;把hudi的元信息同步到hive metadata，可使用persto、spark、hive来查询&lt;/li&gt;
&lt;li&gt;Inputformat可设置&lt;/li&gt;
&lt;li&gt;COW 默认为 HoodieParquetInputFormat&lt;/li&gt;
&lt;li&gt;MOR 可以设置为HoodieParquetRealtimeInputFormat ，这样就可以都读取增量文件（日志文件）&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>重复提交任务的Case</title>
      <link>https://hanzhihua.cn/post/raft_cs_1/</link>
      <pubDate>Tue, 26 Nov 2019 17:19:27 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/raft_cs_1/</guid>
      
        <description>

&lt;p&gt;昨天下午出现了Yarn集群中pending任务增多，整个Hadoop集群变的很慢&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;9点10分钟左右调度系统升级发布&lt;/li&gt;
&lt;li&gt;9点10分钟左右Yarn集群出现大量的pending任务&lt;br /&gt;
&lt;em&gt;注：(pending任务过多了=&amp;gt; ResourceManager 排序慢（同步）=&amp;gt; yarn集群变慢)&lt;/em&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;调度系统中所有Worker节点与Hiveserver连接数 &amp;gt; 1000&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;重启调度系统所有Worker节点，pending任务减少，Yarn又正常工作了&lt;/li&gt;
&lt;li&gt;调度系统在9点10分重启期间，共向Hiveserver提交了近万个任务&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;调度系统的控制节点提交任务的顺序是先提交到Worker节点,然后再修改Raft状态。&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;修改Raft状态和提交任务不是一个事务，采用了最少一次的玩法&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;因为调度系统刚发布，修改Raft任务状态失败，造成不停重复提交任务&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;调度系统的Worker节点对提交的任务是无脑的执行，没有做任何的去重，造成相同的任务重复提交到Hiveserver&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Hive 最大处理线程数设置成 800 （hive.server2.thrift.max.worker.threads=800）&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;重复提交就造成了Yarn出现大量的pending任务&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;重启调度系统的Worker节点，触发Worker节点中的任务转移，因为提交任务是Raft状态修改失败，在控制节点中就没有相关重复提交任务的信息，就不会出现重试现象，也不会再向Hiveserver提交任务&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;改善措施&#34;&gt;改善措施&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;调度系统的控制节点修改提交顺序，采用最多一次+定时轮询超时检查玩法&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;调度系统的Worker节点对提交的任务进行简单的去重&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>ETL线上一个bug</title>
      <link>https://hanzhihua.cn/post/cs_5/</link>
      <pubDate>Tue, 12 Nov 2019 14:00:17 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/cs_5/</guid>
      
        <description>

&lt;p&gt;最近ETL系统偶尔出现执行失败(mysql -&amp;gt; hive)&lt;/p&gt;

&lt;p&gt;失败任务Mysql的数据量规模都是&amp;gt;10亿，而且是多表&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;错误信息&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;执行的SQL为: select * from ***
具体错误信息为：com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure The last packet successfully received from the server was 1 milliseconds ago. 
The last packet sent successfully to the server was 1,058,732 milliseconds ago. 
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;下面是mysql到hive流程分析&lt;br /&gt;


&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/r1.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/r1.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;异常是由Mysql net_write_timeout超时造成的&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;改善措施&#34;&gt;改善措施&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;如果遇到慢节点，快速容错，缩写timeout时间&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;dfs.datanode.socket.write.timeout&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;3000000&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;dfs.socket.timeout&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;3000000&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;针对多表，新增做Task级别的重试，目前是Job级别的重试&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;适当放大net_write_timeout，目前是60s&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;心得&#34;&gt;心得&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;遇到问题，一定不能头痛医头，早期一直在mysqlreader这段找问题，修改各个mysql的性能参数&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;应该研究细节，找到根因，才能处理好问题&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>线上一个小故障</title>
      <link>https://hanzhihua.cn/post/cs_4/</link>
      <pubDate>Tue, 05 Nov 2019 15:36:16 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/cs_4/</guid>
      
        <description>

&lt;p&gt;昨天晚上DAG系统版本发布，出现了部分计算任务不能运行现象&lt;br /&gt;
影响范围：Hive任务、Spark任务(非SQL)&lt;br /&gt;
耗时:半个小时左右&lt;/p&gt;

&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;

&lt;p&gt;DAG任务是按照部门来分对队列的&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;分manual、adhoc、etl&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;etl又分L0、L1、L2&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;版本发布后，陆续收到用户的反馈，任务跑不动，全部提交到了Default队列(这个队列只有很少的资源)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;零时放大Default队列的资源，所有任务都正常运行&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;修复DAG系统，计算任务都正确的进入该进入的队列&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;等在Default队列的任务基本完成，再把Default队列资源回收&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;根因：这个版本引入Raft协议，状态机中的内容丢失了YARN队列的信息&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;测试环境没有测试出来的原因，是测试环境的Default队列也是小部分资源的，测试的任务都可以正常运行，另外就是我们的Checklist不完整，没有覆盖后面的基础设施&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;问题发现由用户发现主要原因，版本上线后的验收测试不完整（只跑了少量任务(因为Default队列是有少量资源的)没有发现错误）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;插曲&#34;&gt;插曲&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;修复版本发布时，出现了一个服务器上面的DAG系统没有正常启动，因为DAG服务需要的端口被其他占用&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;发现占用了该端口的应用是不需要这个端口的，原因是把这个端口做为了TCP的动态端口使用&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;改善措施&#34;&gt;改善措施&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;完善版本上线的Checklist,覆盖后面的基础服务（目前加上队列Check）&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;规范版本上线后的验收测试，如果底层基础架构变化需跑完整的Checklist&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;合理设置TCP动态端口的范围，目前是1024~65535（目前服务部署架构是一台服务器部署多个应用）&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>线上一个小故障</title>
      <link>https://hanzhihua.cn/post/cs_3/</link>
      <pubDate>Tue, 22 Oct 2019 13:03:07 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/cs_3/</guid>
      
        <description>

&lt;p&gt;昨天线上运行的调度系统，又出了一个故障&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;p&gt;因为跟业务强相关，这个忽略&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;p&gt;主要原因就是一个很重要的线程莫名其妙的消失了，下面是该线程的runnalbe的伪代码&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void run(){
                try{
                    业务逻辑
                }catch(Exception e){
                    异常处理   
                }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一般如果直接实现Runnalbe,这个算是标配&lt;br /&gt;
跟踪日志，并没有发现错误日志的出现，开始怀疑应该是有Error,或者Throwable的这样的错误&lt;br /&gt;
突然发现业务逻辑中有这样的代码片段&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;assert  channel != null;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;又发现启动程序中JVM已经使用了 -ea参数，问题找到了，就是assert抛出了Error造成的&lt;/p&gt;

&lt;p&gt;再度分析，为什么channel会为空（当前NIO框架是Netty）,后来发现代码中Overrider了下面两个方法&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void channelActive(ChannelHandlerContext ctx) throws Exception
public void channelInactive(ChannelHandlerContext ctx) throws Exception 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;根因找到了，因为这个两个事件触发的顺序问题，造成了channal为空&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;记住：当发生channal快速重连的情况，上述两个方法不能保证的触发顺序&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这次异常就是因为channelActive事件先于channelInactive事件触发&lt;/p&gt;

&lt;h2 id=&#34;改善措施&#34;&gt;改善措施&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;放弃使用java assert断言，使用其他第三方的断言处理方案，目前采用Guava的Preconditions&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;放弃把业务逻辑放在netty事件里处理，也放弃Netty，准备自己重新实现NIO框架，这样可控&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>RPC协议设计</title>
      <link>https://hanzhihua.cn/post/rpc_pro_1/</link>
      <pubDate>Sat, 19 Oct 2019 13:27:58 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/rpc_pro_1/</guid>
      
        <description>

&lt;p&gt;NIO框架、RPC服务都需要设计私有通信协议，包括协议头+协议体&lt;/p&gt;

&lt;h3 id=&#34;协议头&#34;&gt;协议头&lt;/h3&gt;

&lt;p&gt;一般包括：MagicCode+协议版本+请求类型(req/reps/oneway)+保留字段（特殊字段）+报文头长度+报文体长度+RequestID+序列化类型&lt;/p&gt;

&lt;p&gt;协议头长度一般是固定的，一般包含一些不需要做反序列化就可以读的特殊字段&lt;/p&gt;

&lt;h3 id=&#34;协议体&#34;&gt;协议体&lt;/h3&gt;

&lt;p&gt;一般就是序列化Byte数组，可以是PB序列化，或者Hessian序列化等&lt;/p&gt;

&lt;h2 id=&#34;encoder-decoder&#34;&gt;encoder/decoder&lt;/h2&gt;

&lt;p&gt;NIO框架一般是需要Bytebuf这种数据结构，需要支持increase，descrease功能&lt;/p&gt;

&lt;h2 id=&#34;读操作-decoder&#34;&gt;读操作（decoder）&lt;/h2&gt;

&lt;p&gt;读操作一般流程是&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;flip（转成读模式）&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;decode(解码)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;compact （删除读过的字节）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;读协议体&#34;&gt;读协议体&lt;/h3&gt;

&lt;p&gt;流程一般是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;判断buffer可用长度是否大于协议头长度，如果不满足等待下一次读&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;检查MagicCode&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;读协议体-1&#34;&gt;读协议体&lt;/h3&gt;

&lt;p&gt;流程一般是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;判断buffer可用长度是否大于报文体长度，如果不满足等待下一次读&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;根据序列化类型，做反序列化形成对象&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;写操作-encoder&#34;&gt;写操作(encoder)&lt;/h2&gt;

&lt;p&gt;流程一般是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;准备需要传送的对象&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;序列化对象，形成字节数组&lt;/li&gt;
&lt;li&gt;生成一个bytebuffer，设置头信息&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;设置Body信息&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;发送：）&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>hive/spark server-jdbc连接池问题</title>
      <link>https://hanzhihua.cn/post/cpool_1/</link>
      <pubDate>Fri, 11 Oct 2019 16:38:07 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/cpool_1/</guid>
      
        <description>

&lt;p&gt;&lt;strong&gt;昨天线上DAG系统出现了连接池的问题&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;p&gt;昨天部分服务器做内存扩容，这些服务器上面跑着包括*hivethrift/sparkthrift server*等服务&lt;/p&gt;

&lt;p&gt;用户在adhoc操作时出现异常&lt;/p&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;p&gt;用户的adhoc操作走的是jdbc协议，而数据库服务器的节点配置是在上面的服务器上随机了配置三台服务器&lt;/p&gt;

&lt;p&gt;执行节点使用了durid连接池，随机在三台服务器找一台作为数据库服务器来建立并维护连接&lt;/p&gt;

&lt;p&gt;如果这个时候该服务器重启，那么就会发生org.springframework.jdbc.CannotGetJdbcConnectionException 异常，&lt;/p&gt;

&lt;p&gt;并且在服务器没有重启完成时不能自愈&lt;/p&gt;

&lt;p&gt;&lt;em&gt;为什么采取jdbc方式，主要是利用连接池中的长连接，以提高adhoc 检测/执行的性能&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;改善措施&#34;&gt;改善措施&lt;/h2&gt;

&lt;p&gt;不大改，采用简单处理方式，如果后续再出现org.springframework.jdbc.CannotGetJdbcConnectionException 异常时，&lt;/p&gt;

&lt;p&gt;可以推断出改hivethrift/springthrift server重启了&lt;/p&gt;

&lt;p&gt;处理方式：&lt;strong&gt;剔除该节点，在列表中重新选择其他的一个节点建立连接池&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;其他&#34;&gt;其他&lt;/h2&gt;

&lt;p&gt;如果hiveserver对比mysqlserver,数据库节点出现问题，一般使用以下方式处理&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;没有采用DNS的应用，一般是应用修改配置，重启应用来解决&lt;/li&gt;
&lt;li&gt;采用DNS的应用，运维手动修改DNS配置，并清除DNS缓存来完成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;两个都比较耗时的&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>IO模型比较</title>
      <link>https://hanzhihua.cn/post/io_2/</link>
      <pubDate>Wed, 09 Oct 2019 13:01:30 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/io_2/</guid>
      
        <description>

&lt;h2 id=&#34;io模型&#34;&gt;IO模型&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;IO请求划分两个阶段：

&lt;ul&gt;
&lt;li&gt;等待数据就绪&lt;/li&gt;
&lt;li&gt;从内核缓冲区(socket send/receive buffer)拷贝到进程内存中&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;安全请求是否堵塞

&lt;ul&gt;
&lt;li&gt;同步IO&lt;/li&gt;
&lt;li&gt;异步IO&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Unix的几种IO模型

&lt;ul&gt;
&lt;li&gt;阻塞IO （BIO）&lt;/li&gt;
&lt;li&gt;IO复用  (NIO)&lt;/li&gt;
&lt;li&gt;异步IO  (AIO)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;io模型之间的区别&#34;&gt;IO模型之间的区别&lt;/h2&gt;



&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/io_c.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/io_c.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;h2 id=&#34;io策略&#34;&gt;IO策略&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;BIO:每个client一个线程&lt;/li&gt;
&lt;li&gt;NIO:单线程，多个client,非阻塞（IO复用）

&lt;ul&gt;
&lt;li&gt;水平触发&lt;/li&gt;
&lt;li&gt;边缘触发&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;AIO: 单线程，多个client&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;nio-aio比较&#34;&gt;NIO,AIO比较&lt;/h2&gt;

&lt;p&gt;NIO通过一个selectdor(注册器)来最轮询监听连接和读取数据，内核依赖epoll来实现
需要写代码来实现轮询，一般是利用nio框架
AIO不需要selector这样东西，有内核来实现，数据准备完成后来通知应用
不需要更多的代码&lt;/p&gt;

&lt;h3 id=&#34;aio实现&#34;&gt;AIO实现&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Windows: IOCP&lt;/li&gt;
&lt;li&gt;Linux: epoll模拟
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>安全相关</title>
      <link>https://hanzhihua.cn/post/sec_1/</link>
      <pubDate>Sun, 06 Oct 2019 10:25:14 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/sec_1/</guid>
      
        <description>

&lt;h2 id=&#34;安全规范&#34;&gt;安全规范&lt;/h2&gt;

&lt;h3 id=&#34;数据安全&#34;&gt;数据安全&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;数据使用安全&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;数据库加密&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;日志敏感字段脱敏&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;网络安全规范&#34;&gt;网络安全规范&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;HTTPS 规范&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;端口规范&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;运维安全&#34;&gt;运维安全&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;服务器漏洞&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Nginx 运维安全规范&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;default_server 建议直接配置为一个 403 页面&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;设置location和alias的值都带有后缀&amp;rdquo;/&amp;rdquo;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;确保 proxy_pass 参数用户不可控&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;敏感服务使用规范

&lt;ul&gt;
&lt;li&gt;敏感服务包括：JAVA JMX RMI、Docker Remote API、Redis、MySQL、管理后台&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;主机安全规范

&lt;ul&gt;
&lt;li&gt;操作系统 SSH 安全加固配置项

&lt;ul&gt;
&lt;li&gt;PasswordAuthentication no&lt;/li&gt;
&lt;li&gt;ChallengeResponseAuthentication no&lt;/li&gt;
&lt;li&gt;UsePAM yes&lt;/li&gt;
&lt;li&gt;systemctl reload sshd&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;国家政策安全规范&#34;&gt;国家政策安全规范&lt;/h3&gt;

&lt;h3 id=&#34;业务-应用层安全规范&#34;&gt;业务&amp;amp;应用层安全规范&lt;/h3&gt;

&lt;h1 id=&#34;最佳实践&#34;&gt;最佳实践&lt;/h1&gt;

&lt;h2 id=&#34;生产网络安全&#34;&gt;生产网络安全&lt;/h2&gt;

&lt;h3 id=&#34;ddos&#34;&gt;DDOS&lt;/h3&gt;

&lt;h3 id=&#34;系统后门告警排查&#34;&gt;系统后门告警排查&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;排查方向&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;挖矿程序 服务器CPU资源使用情况&lt;/li&gt;
&lt;li&gt;DDOS木马 服务器出流量情况
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可疑文件创建时间，以此时间排查其他文件是否有改动：stat filename（modify与change时间相差过大以change时间为主）&lt;/p&gt;

&lt;p&gt;可疑文件句柄：lsof&lt;/p&gt;

&lt;p&gt;可疑进程运行权限：ps（排查相应权限运行的 服务/应用 是否存在漏洞等）&lt;/p&gt;

&lt;p&gt;命令是否被篡改： ps/ls/netstat/ss/top 等命令（排查命令文件修改时间/md5、ls -alt &amp;ndash;sort=time /bin/）&lt;/p&gt;

&lt;p&gt;服务器登录记录：auth.log/secure/sshd.log、last&lt;/p&gt;

&lt;p&gt;cron任务排查：/etc/cron*、/var/spool/cron&lt;/p&gt;

&lt;p&gt;可疑用户：/etc/passwd&lt;/p&gt;

&lt;p&gt;SSH 公钥：/root/.ssh/authorized_keys（文件是否有改动）&lt;/p&gt;

&lt;p&gt;SSH 配置：/etc/ssh/sshd_config（文件是否有改动、是否运行密码登录）&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;主机安全&#34;&gt;主机安全&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;账号排查

&lt;ul&gt;
&lt;li&gt;启用账号列表：root，ansible&lt;/li&gt;
&lt;li&gt;是否支持使用密码登录主机：root 允许key和密码登录，但无弱口令情况&lt;/li&gt;
&lt;li&gt;系统内各个账号的公钥是否异常：否&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;端口排查

&lt;ul&gt;
&lt;li&gt;端口监听程序是否为已知程序&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;进程排查

&lt;ul&gt;
&lt;li&gt;是否为已知业务的正常进&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;操作审计

&lt;ul&gt;
&lt;li&gt;近期内可疑的命令行操作记录：30 天内未发现敏感操作&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;入侵检测

&lt;ul&gt;
&lt;li&gt;是否部署主机入侵检测系统&lt;/li&gt;
&lt;li&gt;是否支持 BASH 安全审计&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;定时任务

&lt;ul&gt;
&lt;li&gt;排查未发现可疑定时任务&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;外网端口访问:&lt;/li&gt;
&lt;li&gt;标准进程和标准端口&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;杀毒软件-针对centos系统举例&#34;&gt;杀毒软件 (针对centos系统举例)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;inux 下面一般是不说病毒，至少漏洞，但windows转过来的运维同学还是习惯要按照杀毒软件，linux下面也是有查杀病毒软件（&lt;a href=&#34;https://www.clamav.net/&#34;&gt;Clamav&lt;/a&gt;）&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;安装方式：yum install -y epel-release &amp;amp;&amp;amp; yum install -y clamav &amp;amp;&amp;amp; freshclam&lt;/li&gt;
&lt;li&gt;杀毒脚本：
    * clamscan –ri / -l clamscan.log &amp;ndash;remove （查杀整个系统）&lt;br /&gt;
    * clamscan  -ri /root -l /tmp/clamscan.log &amp;ndash;move=/tmp/clav (例子)&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;升级-补丁-针对centos系统举例&#34;&gt;升级/补丁 (针对centos系统举例)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;查看版本：cat /etc/redhat-release&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;升级：yum update -y&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;检查安全相关：yum &amp;ndash;security check-update&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;升级安全相关：yum &amp;ndash;security upgrade&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;弱口令修复方案&#34;&gt;弱口令修复方案&lt;/h3&gt;

&lt;p&gt;弱口令主要包含 SSH、MySQL、Redis、rsync、ftp等服务。&lt;/p&gt;

&lt;h2 id=&#34;各种安全系统&#34;&gt;各种安全系统&lt;/h2&gt;

&lt;h3 id=&#34;waf相关&#34;&gt;WAF相关&lt;/h3&gt;

&lt;p&gt;Web APP 防火墙：恶意攻击拦截、拦截数据分析、限制 API 访问频率等&lt;/p&gt;

&lt;h4 id=&#34;流量访问频率限制&#34;&gt;流量访问频率限制&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;IP 访问频率限制&amp;amp;封禁&lt;/li&gt;
&lt;li&gt;Session 访问频率限制&amp;amp;封禁&lt;/li&gt;
&lt;li&gt;默认无频率限制，需对域名或URL进行配置&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;主机入侵检测系统&#34;&gt;主机入侵检测系统&lt;/h3&gt;

&lt;p&gt;安装部署、问题跟进、主机安全相关&lt;/p&gt;

&lt;h3 id=&#34;业务风控系统&#34;&gt;业务风控系统&lt;/h3&gt;

&lt;p&gt;帐号体系、内容体系、高频业务流量等&lt;/p&gt;

&lt;h3 id=&#34;舆情监控系统&#34;&gt;舆情监控系统&lt;/h3&gt;

&lt;p&gt;监控 Github&amp;amp;Gitlab 代码泄露、微博发表安全相关言论监控等&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Raft简介</title>
      <link>https://hanzhihua.cn/post/raft_2/</link>
      <pubDate>Sat, 05 Oct 2019 23:26:57 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/raft_2/</guid>
      
        <description>

&lt;h2 id=&#34;什么是raft协议&#34;&gt;什么是Raft协议&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;一致性算法&lt;/li&gt;
&lt;li&gt;解决分布式系统多副本的一致性&lt;/li&gt;
&lt;li&gt;集群高可用（在部分节点不工作时）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;状态机&#34;&gt;状态机&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;响应外部请求的&lt;/li&gt;
&lt;li&gt;管理内部的状态&lt;/li&gt;
&lt;li&gt;例子：Memcache、redis


&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_sm.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_sm.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;复制状态机&#34;&gt;复制状态机&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;日志复制确保各个节点状态机执行相同的命令及相同的顺序&lt;/li&gt;
&lt;li&gt;一致性模块确保日志正确的复制&lt;/li&gt;
&lt;li&gt;在大部分机器存活时，系统能正常工作，&lt;/li&gt;
&lt;li&gt;故障模型：丢消息、消息验收，fail-stop，不会产生随机故障（Byzantine）


&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_rp_sm.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_rp_sm.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;raft分解&#34;&gt;Raft分解&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Leader选举

&lt;ul&gt;
&lt;li&gt;只有一个节点可以做为Leader&lt;/li&gt;
&lt;li&gt;侦测crashes, 选择新的Leader&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;日志复制

&lt;ul&gt;
&lt;li&gt;Leader接受Client请求，转成日志&lt;/li&gt;
&lt;li&gt;Leader复制日志到其他的节点&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;安全性

&lt;ul&gt;
&lt;li&gt;日志的一致性&lt;/li&gt;
&lt;li&gt;只有拥有最新的日志的节点才可以成为Leader&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;节点状态和rpc&#34;&gt;节点状态和RPC&lt;/h2&gt;



&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_s_rpc.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_s_rpc.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;h2 id=&#34;terms&#34;&gt;Terms&lt;/h2&gt;



&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_term.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_term.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;每一个term最多只有一个leader&lt;/li&gt;
&lt;li&gt;有的term没有leader（选举失败）&lt;/li&gt;
&lt;li&gt;每个节点维护自己的term

&lt;ul&gt;
&lt;li&gt;在每次rpc过程中交换&lt;/li&gt;
&lt;li&gt;Peer有更大的term,setpdown成为follower&lt;/li&gt;
&lt;li&gt;请求包含无效的term，就丢弃&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;leader选举&#34;&gt;Leader选举&lt;/h2&gt;



&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_l_ele.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_l_ele.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;h2 id=&#34;选举的正确性&#34;&gt;选举的正确性&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;安全性：允许每个term最多一个winner

&lt;ul&gt;
&lt;li&gt;每个节点每个term只能头一次票&lt;/li&gt;
&lt;li&gt;获得大多数票才能赢得选举&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Liveness：要有一个Candidate获得选举

&lt;ul&gt;
&lt;li&gt;选举超时时间是随机在[T,2T]&lt;/li&gt;
&lt;li&gt;一个节点可以依赖timeout来赢得选举&lt;/li&gt;
&lt;li&gt;T &amp;gt;&amp;gt; 广播时间&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;随机timeout方法比Ranking方法简单&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;操作流程&#34;&gt;操作流程&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Client 发送命令到Leader&lt;/li&gt;
&lt;li&gt;Leader 把命令 append到它的log中&lt;/li&gt;
&lt;li&gt;Leader 发送 AppendEntries RPCs 给所有的followers&lt;/li&gt;
&lt;li&gt;一旦命令 提交：

&lt;ul&gt;
&lt;li&gt;Leader 在它的状态机中执行命令，返回结果给Client&lt;/li&gt;
&lt;li&gt;Leader 在下一次AppendEntriesRPS通知followers，提交命令&lt;/li&gt;
&lt;li&gt;Followers在它的状态机中执行命令&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Crashed/slow followers

&lt;ul&gt;
&lt;li&gt;Leader 重试 AppendEntries RPCs 直到它们成功
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;日志结构&#34;&gt;日志结构&lt;/h2&gt;

&lt;p&gt;

&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_l_s.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_l_s.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;

* 当节点crash时，日志必须保存（需要落盘）
* Committed的entry必须被状态机执行过
   * 当日志存在多个节点上（被复制）&lt;/p&gt;

&lt;h2 id=&#34;日志不一致性&#34;&gt;日志不一致性&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;节点crash造成了日志的不一致性


&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_l_i.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_l_i.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;Raft修复日志不一致方法

&lt;ul&gt;
&lt;li&gt;Leader的日志是正确的&lt;/li&gt;
&lt;li&gt;Leader会帮助follower使用修复日志&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;日志匹配特征&#34;&gt;日志匹配特征&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;如果日志记录在不同节点有相同的index和term

&lt;ul&gt;
&lt;li&gt;他们存储相同的命令&lt;/li&gt;
&lt;li&gt;之前的日志记录也是完全相同的


&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_l_m.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_l_m.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如果一个日志记录被Committed过，那么所有之前的日志记录都被Committed&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;appendentries-一致性检查&#34;&gt;AppendEntries 一致性检查&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;AppendEntries RPCs 包含当前日志及前一个日志&lt;index,term&gt;&lt;/li&gt;
&lt;li&gt;Follower需要匹配前一个的日志的，否则将拒绝请求

&lt;ul&gt;
&lt;li&gt;Leader 使用前一个日志重试&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;实现，需要满足日志匹配特征


&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_l_c.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_l_c.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;安全性-leader完整性&#34;&gt;安全性：Leader完整性&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;一旦日志记录committed,后面的Leader必须存储这个日志记录&lt;/li&gt;
&lt;li&gt;节点包含没有完成的日志记录不能赢得选举

&lt;ul&gt;
&lt;li&gt;Candidate包含最后日志记录&lt;/li&gt;
&lt;li&gt;Voting 服务器拒绝投票，如果它的日志是更新&lt;/li&gt;
&lt;li&gt;日志排序根据最后的term和index&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>线上死锁问题分析</title>
      <link>https://hanzhihua.cn/post/dl_1/</link>
      <pubDate>Sun, 29 Sep 2019 14:13:34 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/dl_1/</guid>
      
        <description>

&lt;p&gt;最近线上DAG系统居然出现了死锁问题&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;p&gt;DAG系统新版本发布，系统启动过程中在获取连接时出现了hang住的现象&lt;/p&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;DAG系统包括两个组件（控制节点和工作节点），控制节点在接受用户请求或者启动时都会主动连接工作节点&lt;br /&gt;
连接过程中，包括一个session建立的初始化请求（类似于zookeeper 客户端连接服务），session init后连接工作才算完成&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;过程中两把锁，一个是连接建立是需要的socket锁和一个是节点track是需要的session锁&lt;/li&gt;
&lt;li&gt;代码中使用了jvm锁机制，使用了synchronized 关键字&lt;/li&gt;
&lt;li&gt;系统启动时，需要节点track初始化session，需要获得session锁，而同时又需要接受用户请求需要初始化连接,使用的是socket锁&lt;/li&gt;
&lt;li&gt;节点track需要初始化连接，需要socket锁&lt;/li&gt;
&lt;li&gt;初始化连接又需要初始化session，需要session锁&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;尽量避免锁的嵌套&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;session,socket两把锁在业务语义上是一样的，可以直接修改成一把锁&lt;/li&gt;
&lt;li&gt;也可以用concurrent包lock对象，利用超时机制避免死锁出现&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>个人搭建VPN代理</title>
      <link>https://hanzhihua.cn/post/ss_1/</link>
      <pubDate>Wed, 18 Sep 2019 14:00:34 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/ss_1/</guid>
      
        <description>

&lt;p&gt;作为一个技术人员，不能上google的话，工作效率会下降很多，所以我们需要一个VPN&lt;br /&gt;
可以通过购买VPN服务，或者自行搭建VPN服务&lt;br /&gt;
因为购买的VPN服务经常会被墙，所以选择自行搭建VPN服务，缺点：最好只上Google,其他需要考虑流量成本&lt;/p&gt;

&lt;h2 id=&#34;搭建vpn方法&#34;&gt;搭建VPN方法&lt;/h2&gt;

&lt;h3 id=&#34;申请aws-免费空间&#34;&gt;申请AWS 免费空间&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;选择Amazon EC2免费套餐(1年内免费)，实例类型 t2.micro，可以选择东京或者韩国地区&lt;/li&gt;
&lt;li&gt;下载pem文件，需要通过它来做ssh登录，命令 &lt;code&gt;ssh -i &amp;quot;***.pem&amp;quot; ec2-user@****.compute.amazonaws.com&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;在安全组中加上一个自定义 TCP 规则，配置你的VPN端口&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;vpn-软件安装&#34;&gt;VPN 软件安装&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;软件选择 &lt;a href=&#34;https://github.com/shadowsocks/go-shadowsocks2&#34;&gt;go-shadowsocks2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;可直接下载已经编译完成的包，如果了解golang,可自行编译&lt;/li&gt;
&lt;li&gt;启动软件 &lt;code&gt;shadowsocks2 -s &#39;ss://AES-128-CFB:你的密码@[]:你的端口&#39; -verbose&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;安装ss 客户端即可&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>JAVA 处理信号</title>
      <link>https://hanzhihua.cn/post/sig_1/</link>
      <pubDate>Sat, 14 Sep 2019 17:27:28 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/sig_1/</guid>
      
        <description>

&lt;h2 id=&#34;信号&#34;&gt;信号&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;在终端查看所有的信号，可以通过 &lt;code&gt;kill -l&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;给指定进程发送信号，&lt;code&gt;kill -s ** pid&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;详情 &lt;code&gt;man kill&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;java中处理信号方法&#34;&gt;java中处理信号方法&lt;/h2&gt;

&lt;h3 id=&#34;注册信号&#34;&gt;注册信号&lt;/h3&gt;

&lt;p&gt;需要预先判断rt.jar中是否包含sun.misc.Signal&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;try {
            Class.forName(&amp;quot;sun.misc.Signal&amp;quot;);
        } catch (final Throwable t) {
            if (LOG.isWarnEnabled()) {
                LOG.warn(&amp;quot;sun.misc.Signal: unavailable, {}.&amp;quot;, t);
            }
            return;
        }
final sun.misc.Signal signal = new sun.misc.Signal(signalName);
final sun.misc.SignalHandler handler = ...;
sun.misc.Signal.handle(signal, handler);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;处理信号&#34;&gt;处理信号&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;实现 sun.misc.SignalHandler接口 即可&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>线上zookeeper使用中的一个坑</title>
      <link>https://hanzhihua.cn/post/zk_3/</link>
      <pubDate>Thu, 12 Sep 2019 19:21:33 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/zk_3/</guid>
      
        <description>

&lt;p&gt;线上DAG又出现BUG了，这个系统BUG还真多&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;DAG系统的执行节点重启发布&lt;/li&gt;
&lt;li&gt;正常流程 执行节点stop，自动摘掉zookeeper上面的EPHEMERAL节点，执行节点start，再重新挂上zookeeper EPHEMERAL节点，接受控制节点的调度。&lt;/li&gt;
&lt;li&gt;但这次发布过程中stop流程耗时比较长，最后发布系统采用kill -9 方式结束进程&lt;/li&gt;
&lt;li&gt;start流程正常启动，zookeeper 节点正常挂上&lt;/li&gt;
&lt;li&gt;但该zookeeper节点会莫名消失，而应用却是一切正常的，所以该执行节点无法被控制节点发现，也就无法正常工作&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;问题找到了，主要出现在挂节点流程中，代码如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private void registerExecuteNode() throws Exception {
    // 启动 重试
    int retryTimes = 0;
    do {
        retryTimes++;
        upsertExecuteZNode(convert(currentNode));
        LOGGER.info(&amp;quot;register execute node {} tries&amp;quot;, retryTimes);
    } while (zNodeDao.getExecuteZNode(currentNode.getId()) == null &amp;amp;&amp;amp; retryTimes &amp;lt; REGISTER_RETRY_COUNTS);
    if (zNodeDao.getExecuteZNode(currentNode.getId()) == null) {
        throw new RegisterFailedException(&amp;quot;register execute node error&amp;quot;);
    }
}
public void upsertExecuteZNode(ExecuteZNode executeZNode) throws Exception {

    try {
        String path = ...;
        zkClientTemplate.writeData(path, false, serialization(executeZNode)); //问题出现在这里
    } catch (Exception e) {
        LOGGER.error(&amp;quot;create or update execute znode error {}&amp;quot;, BilibiliSerializeUtils.toJSON(executeZNode), e);
        throw e;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;问题主要出现在zkClientTemplate.writeData，该方法会检查path是否存在，如果存在，那么就更新该节点内容。&lt;/p&gt;

&lt;p&gt;因为进程是被kill -9 强制关闭的，那么zookeeper上的节点就可能是由被kill的进程建立，新进程只是简单的更新了改节点的内容，而这个节点会因为zookeeper的session过期被zookeeper移除&lt;/p&gt;

&lt;h2 id=&#34;修复&#34;&gt;修复&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;应用启动时，先检查zookeeper是否有该节点，如果有，就先删除，然后重新建立新的节点&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;zookeeper的坑&#34;&gt;zookeeper的坑&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;zookeeper的EPHEMERAL的节点是有过期时间的，如果进程没有正确的告知zookeeper删除该节点（主要是正常的执行完成zookeepr.close 方法）
那么该节点不会因为进程的消失而马上消失&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>hiveserver2重启后的BUG</title>
      <link>https://hanzhihua.cn/post/hive_bug1/</link>
      <pubDate>Wed, 11 Sep 2019 14:22:59 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/hive_bug1/</guid>
      
        <description>

&lt;p&gt;昨天晚上，hiveserver2重启发布了，线上DAG系统查询hive时出现大量的broken pipe错误&lt;/p&gt;

&lt;p&gt;DAG系统使用了jdbc连接池方式来访问hiveserver2，感觉使用了无效的连接，而这些无效的连接一直保留在连接池中，不能被回收&lt;/p&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;jdbc协议使用了连接池，利用第三方连接池(druid)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;配置如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jdbc.driver=org.apache.hive.jdbc.HiveDriver
jdbc.url=***
jdbc.user=***
jdbc.pwd=***
jdbc.initialSize=16
jdbc.maxActive=64
jdbc.maxIdle=60000
jdbc.maxWait=10000
jdbc.eviction_interval = 60000L
jdbc.testOnBorrow = false
jdbc.testOnReturn = false
jdbc.testWhileIdle = true
jdbc.validation_query  = &amp;quot;select 1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配置说明&#34;&gt;配置说明&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;连接池中的连接只有在空闲的时候做检查，如果该连接一直在使用，则不做检查，空闲时间超过(eviction_interval) 60s则会做连接检查&lt;/li&gt;
&lt;li&gt;检查语句为 &amp;ldquo;select 1&amp;rdquo;&lt;/li&gt;
&lt;li&gt;说明一个问题，如果hiveserver2重启后，如果1分钟内没有进行adhoc查询，那么什么事情也不会发生，你好我好，1分钟后所有坏的连接都被回收,重新建立&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;很不巧，昨天我们的thriftserver2重启后，不停的有人来访问，搞的大家紧张兮兮&lt;/p&gt;

&lt;p&gt;另外连接池有一个非常重要的东西是*ExceptionSorter*，它会根据SQLException中的errorCode来判断是否要真正的关闭连接。
我们选择的是Druid连接池，它的逻辑如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; for (Class&amp;lt;?&amp;gt; driverClass = driver.getClass();;) {
            String realDriverClassName = driverClass.getName();
            if (realDriverClassName.equals(JdbcConstants.MYSQL_DRIVER) //
                    || realDriverClassName.equals(JdbcConstants.MYSQL_DRIVER_6)) {
                this.exceptionSorter = new MySqlExceptionSorter();
                this.isMySql = true;
            } else if (realDriverClassName.equals(JdbcConstants.ORACLE_DRIVER)
                    || realDriverClassName.equals(JdbcConstants.ORACLE_DRIVER2)) {
                this.exceptionSorter = new OracleExceptionSorter();
            } else if (realDriverClassName.equals(&amp;quot;com.informix.jdbc.IfxDriver&amp;quot;)) {
                this.exceptionSorter = new InformixExceptionSorter();

            } else if (realDriverClassName.equals(&amp;quot;com.sybase.jdbc2.jdbc.SybDriver&amp;quot;)) {
                this.exceptionSorter = new SybaseExceptionSorter();

            } else if (realDriverClassName.equals(JdbcConstants.POSTGRESQL_DRIVER)
                    || realDriverClassName.equals(JdbcConstants.ENTERPRISEDB_DRIVER)) {
                this.exceptionSorter = new PGExceptionSorter();

            } else if (realDriverClassName.equals(&amp;quot;com.alibaba.druid.mock.MockDriver&amp;quot;)) {
                this.exceptionSorter = new MockExceptionSorter();
            } else if (realDriverClassName.contains(&amp;quot;DB2&amp;quot;)) {
                this.exceptionSorter = new DB2ExceptionSorter();

            } else {
                Class&amp;lt;?&amp;gt; superClass = driverClass.getSuperclass();
                if (superClass != null &amp;amp;&amp;amp; superClass != Object.class) {
                    driverClass = superClass;
                    continue;
                }
            }

            break;
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们使用的是org.apache.hive.jdbc.HiveDriver，算出来的ExceptionSort为空，那么这个补救的门也被关闭了，如果一直在使用，那么就只有一直的错下去&lt;/p&gt;

&lt;h2 id=&#34;bug修复方法&#34;&gt;bug修复方法&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;因为写一个ExceptionSort成本比较高，所以就在取的连接的时候，做一次连接可用性的检查，testOnBorrow设置为true&lt;/li&gt;
&lt;li&gt;validation_query  = &amp;ldquo;select 1&amp;rdquo;,对于普通的关系型数据库是一个比较好的选择，但对应hive就非常慢了,改成 &amp;ldquo;show databases&amp;rdquo; 就会快很多&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>HADOOP集群 健康状况检测方案</title>
      <link>https://hanzhihua.cn/post/sre_1/</link>
      <pubDate>Tue, 10 Sep 2019 11:09:03 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/sre_1/</guid>
      
        <description>

&lt;h2 id=&#34;hadoop集群-健康状况检测方案&#34;&gt;HADOOP集群 健康状况检测方案&lt;/h2&gt;

&lt;p&gt;流程：对linux的日志进行监控，当发生错误时候，对硬盘或者机器做下线处理&lt;/p&gt;

&lt;h3 id=&#34;监控方法&#34;&gt;监控方法&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;文件:/var/log/syslog  ,内容: &amp;ldquo;NIC Link is Down&amp;rdquo;,直接下线该机器&lt;/li&gt;
&lt;li&gt;文件::/var/log/syslog ,内容: &amp;ldquo;I/O error&amp;rdquo; 下线该磁盘&lt;/li&gt;
&lt;li&gt;文件::/var/log/syslog ,内容: &amp;ldquo;blk_update_request: critical medium error&amp;rdquo; 下线该磁盘&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>一个DAG系统的故障</title>
      <link>https://hanzhihua.cn/post/cs_2/</link>
      <pubDate>Thu, 05 Sep 2019 14:06:22 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/cs_2/</guid>
      
        <description>

&lt;p&gt;昨天线上DAG系统一个工作节点出现了OOM。
线上处理问题流程：&lt;strong&gt;先止损，后定位&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;收到DAG系统一个工作节点的OOM告警&lt;/li&gt;
&lt;li&gt;查看DAG系统工作状态，发现DAG系统的调度任务工作正常&lt;/li&gt;
&lt;li&gt;查看监控系统，系统层面正常，该节点已经重启&lt;/li&gt;
&lt;li&gt;通过查看该节点的日志，没有发现特别的地方&lt;/li&gt;
&lt;li&gt;查找JVM crash的日志，但没有找到&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;问题分析-节点oom原因&#34;&gt;问题分析（节点OOM原因）&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;通过监控系统，发现该节点接受的工作请求与其他工作节点没有什么区别，而且crash 节点日志没有特别的地方。
多个工作节点，但只有一个工作节点出现了OOM，感觉是由于任务造成的&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;该节点重启时，并没有dump出内存快照?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;该节点重启是由于OOM而退出，supervisor又把它拉起来&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;进程启动脚本（部分）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-XX:+UseG1GC -XX:ParallelGCThreads=24 
-XX:ConcGCThreads=16 -XX:InitiatingHeapOccupancyPercent=45 
-XX:NewRatio=2 -XX:SurvivorRatio=4 -XX:MaxTenuringThreshold=15 
-XX:-UseAdaptiveSizePolicy -Xms16G -Xmx16G -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/data/log/目录/应用_%p.hprof 
-XX:+PrintGCDetails -Xloggc:/data/log/目录/应用.log -XX:+PrintGCTimeStamps 
-Djava.security.egd=file:/dev/./urandom -Dfile.encoding=utf-8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要的原因，TMD的 &lt;strong&gt;目录/data/log/目录&lt;/strong&gt; 不存在，下面是supervisor日志&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Java HotSpot(TM) 64-Bit Server VM warning: Cannot open file /data/log/目录/... due to No such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;哎，最宝贵的crash的内存快照、异常信息就没有了
留给我们的，只有痛苦的梳理crash节点当时运行过的每个任务了，静态的分析是否可能存在内存泄露情况&lt;/p&gt;

&lt;h2 id=&#34;改善措施&#34;&gt;改善措施&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;建立/data/log/目录/，（目录要建的，不然就是&amp;rsquo;带病&amp;rsquo;工作）&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
  </channel>
</rss>
