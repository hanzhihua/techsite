<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>一个码农 工作点滴</title>
    <link>https://hanzhihua.cn/</link>
    <description>Recent content on 一个码农 工作点滴</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>All rights reserved - 2019 沪ICP备19026538号 </copyright>
    <lastBuildDate>Wed, 11 Sep 2019 14:22:59 +0800</lastBuildDate>
    
        <atom:link href="https://hanzhihua.cn/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>hiveserver2重启后的BUG</title>
      <link>https://hanzhihua.cn/post/hive_bug1/</link>
      <pubDate>Wed, 11 Sep 2019 14:22:59 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/hive_bug1/</guid>
      
        <description>

&lt;p&gt;昨天晚上，hiveserver2重启发布了，线上DAG系统查询hive时出现大量的broken pipe错误&lt;/p&gt;

&lt;p&gt;DAG系统使用了jdbc连接池方式来访问hiveserver2，感觉使用了无效的连接，而这些无效的连接一直保留在连接池中，不能被回收&lt;/p&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;jdbc协议使用了连接池，利用第三方连接池(druid)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;配置如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jdbc.driver=org.apache.hive.jdbc.HiveDriver
jdbc.url=***
jdbc.user=***
jdbc.pwd=***
jdbc.initialSize=16
jdbc.maxActive=64
jdbc.maxIdle=60000
jdbc.maxWait=10000
jdbc.eviction_interval = 60000L
jdbc.testOnBorrow = false
jdbc.testOnReturn = false
jdbc.testWhileIdle = true
jdbc.validation_query  = &amp;quot;select 1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配置说明&#34;&gt;配置说明&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;连接池中的连接只有在空闲的时候做检查，如果该连接一直在使用，则不做检查，空闲时间超过(eviction_interval) 60s则会做连接检查&lt;/li&gt;
&lt;li&gt;检查语句为 &amp;ldquo;select 1&amp;rdquo;&lt;/li&gt;
&lt;li&gt;说明一个问题，如果hiveserver2重启后，如果1分钟内没有进行adhoc查询，那么什么事情也不会发生，你好我好，1分钟后所有坏的连接都被回收,重新建立&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;很不巧，昨天我们的thriftserver2重启后，不停的有人来访问，搞的大家紧张兮兮&lt;/p&gt;

&lt;p&gt;另外连接池有一个非常中的东西是*ExceptionSorter*，它会根据SQLException中的errorCode来判断是否要真正的关闭连接。
我们选择的是Druid连接池，它的逻辑如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; for (Class&amp;lt;?&amp;gt; driverClass = driver.getClass();;) {
            String realDriverClassName = driverClass.getName();
            if (realDriverClassName.equals(JdbcConstants.MYSQL_DRIVER) //
                    || realDriverClassName.equals(JdbcConstants.MYSQL_DRIVER_6)) {
                this.exceptionSorter = new MySqlExceptionSorter();
                this.isMySql = true;
            } else if (realDriverClassName.equals(JdbcConstants.ORACLE_DRIVER)
                    || realDriverClassName.equals(JdbcConstants.ORACLE_DRIVER2)) {
                this.exceptionSorter = new OracleExceptionSorter();
            } else if (realDriverClassName.equals(&amp;quot;com.informix.jdbc.IfxDriver&amp;quot;)) {
                this.exceptionSorter = new InformixExceptionSorter();

            } else if (realDriverClassName.equals(&amp;quot;com.sybase.jdbc2.jdbc.SybDriver&amp;quot;)) {
                this.exceptionSorter = new SybaseExceptionSorter();

            } else if (realDriverClassName.equals(JdbcConstants.POSTGRESQL_DRIVER)
                    || realDriverClassName.equals(JdbcConstants.ENTERPRISEDB_DRIVER)) {
                this.exceptionSorter = new PGExceptionSorter();

            } else if (realDriverClassName.equals(&amp;quot;com.alibaba.druid.mock.MockDriver&amp;quot;)) {
                this.exceptionSorter = new MockExceptionSorter();
            } else if (realDriverClassName.contains(&amp;quot;DB2&amp;quot;)) {
                this.exceptionSorter = new DB2ExceptionSorter();

            } else {
                Class&amp;lt;?&amp;gt; superClass = driverClass.getSuperclass();
                if (superClass != null &amp;amp;&amp;amp; superClass != Object.class) {
                    driverClass = superClass;
                    continue;
                }
            }

            break;
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们使用的是org.apache.hive.jdbc.HiveDriver，算出来的ExceptionSort为空，那么这个补救的门也被关闭了，如果一直在使用，那么就只有一直的错下去&lt;/p&gt;

&lt;h2 id=&#34;bug修复方法&#34;&gt;bug修复方法&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;因为写一个ExceptionSort成本比较高，所以就在取的连接的时候，做一次连接可用性的检查，testOnBorrow设置为true&lt;/li&gt;
&lt;li&gt;validation_query  = &amp;ldquo;select 1&amp;rdquo;,对于普通的关系型数据库是一个比较好的选择，但对应hive就非常慢了,改成 &amp;ldquo;show databases&amp;rdquo; 就会快很多&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>HADOOP集群 健康状况检测方案</title>
      <link>https://hanzhihua.cn/post/sre_1/</link>
      <pubDate>Tue, 10 Sep 2019 11:09:03 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/sre_1/</guid>
      
        <description>

&lt;h2 id=&#34;hadoop集群-健康状况检测方案&#34;&gt;HADOOP集群 健康状况检测方案&lt;/h2&gt;

&lt;p&gt;流程：对linux的日志进行监控，当发生错误时候，对硬盘或者机器做下线处理&lt;/p&gt;

&lt;h3 id=&#34;监控方法&#34;&gt;监控方法&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;文件:/var/log/syslog  ,内容: &amp;ldquo;NIC Link is Down&amp;rdquo;,直接下线该机器&lt;/li&gt;
&lt;li&gt;文件::/var/log/syslog ,内容: &amp;ldquo;I/O error&amp;rdquo; 下线该磁盘&lt;/li&gt;
&lt;li&gt;文件::/var/log/syslog ,内容: &amp;ldquo;blk_update_request: critical medium error&amp;rdquo; 下线该磁盘&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>一个DAG系统的故障</title>
      <link>https://hanzhihua.cn/post/cs_2/</link>
      <pubDate>Thu, 05 Sep 2019 14:06:22 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/cs_2/</guid>
      
        <description>

&lt;p&gt;昨天线上DAG系统一个工作节点出现了OOM。
线上处理问题流程：&lt;strong&gt;先止损，后定位&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;收到DAG系统一个工作节点的OOM告警&lt;/li&gt;
&lt;li&gt;查看DAG系统工作状态，发现DAG系统的调度任务工作正常&lt;/li&gt;
&lt;li&gt;查看监控系统，系统层面正常，该节点已经重启&lt;/li&gt;
&lt;li&gt;通过查看该节点的日志，没有发现特别的地方&lt;/li&gt;
&lt;li&gt;查找JVM crash的日志，但没有找到&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;问题分析-节点oom原因&#34;&gt;问题分析（节点OOM原因）&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;通过监控系统，发现该节点接受的工作请求与其他工作节点没有什么区别，而且crash 节点日志没有特别的地方。
多个工作节点，但只有一个工作节点出现了OOM，感觉是由于任务造成的&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;该节点重启时，并没有dump出内存快照?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;该节点重启是由于OOM而退出，supervisor又把它拉起来&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;进程启动脚本（部分）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-XX:+UseG1GC -XX:ParallelGCThreads=24 
-XX:ConcGCThreads=16 -XX:InitiatingHeapOccupancyPercent=45 
-XX:NewRatio=2 -XX:SurvivorRatio=4 -XX:MaxTenuringThreshold=15 
-XX:-UseAdaptiveSizePolicy -Xms16G -Xmx16G -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/data/log/目录/应用_%p.hprof 
-XX:+PrintGCDetails -Xloggc:/data/log/目录/应用.log -XX:+PrintGCTimeStamps 
-Djava.security.egd=file:/dev/./urandom -Dfile.encoding=utf-8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要的原因，TMD的 &lt;strong&gt;目录/data/log/目录&lt;/strong&gt; 不存在，下面是supervisor日志&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Java HotSpot(TM) 64-Bit Server VM warning: Cannot open file /data/log/目录/... due to No such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;哎，最宝贵的crash的内存快照、异常信息就没有了
留给我们的，只有痛苦的梳理crash节点当时运行过的每个任务了，静态的分析是否可能存在内存泄露情况&lt;/p&gt;

&lt;h2 id=&#34;改善措施&#34;&gt;改善措施&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;建立/data/log/目录/，（目录要建的，不然就是&amp;rsquo;带病&amp;rsquo;工作）&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>DATAX的玩法</title>
      <link>https://hanzhihua.cn/post/etl_1/</link>
      <pubDate>Sun, 01 Sep 2019 22:56:50 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/etl_1/</guid>
      
        <description>

&lt;p&gt;DATAX是阿里开源的一个优秀的ETL工具，使用框架+PLUGIN设计方式，通过依赖ClassLoader来隔离容错，总体设计还不错，被很多公司的数据团队使用&lt;/p&gt;

&lt;p&gt;做一个完整的数据平台的ETL工具，完全依靠DATAX也是不够，它只能算是一个引擎,一个基础,需要做二次开发&lt;/p&gt;

&lt;h2 id=&#34;二次开发功能点&#34;&gt;二次开发功能点&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;ETL主要是被DAG系统使用，所以数据的输入、描述是有DAG系统或者由统一的元信息服务来承担&lt;/li&gt;
&lt;li&gt;ETL需要被DAG的调度管理，一般都是依赖任务&lt;/li&gt;
&lt;li&gt;DAG系统承担着ETL任务引擎集群管理工作，包括路由、容错、服务发现等&lt;/li&gt;
&lt;li&gt;ETL引擎需要提供接口来接受DAG系统的指令，同时还需要上报任务状态、健康状态等工作&lt;/li&gt;
&lt;li&gt;多进程多节点的任务类型没有开源，需要自己实现&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>状态设计一点想法</title>
      <link>https://hanzhihua.cn/post/state_1/</link>
      <pubDate>Sat, 31 Aug 2019 22:56:31 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/state_1/</guid>
      
        <description>

&lt;p&gt;最近看到同事写的一段关于状态设计的代码（DAG项目，用java语言开发）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;ERROR(-1, &amp;quot;说明...&amp;quot;),
INIT(0, &amp;quot;说明...&amp;quot;),
SUCCESS(1, &amp;quot;说明...&amp;quot;),
FAILED(2, &amp;quot;说明...&amp;quot;),
RUNNING(3, &amp;quot;说明...&amp;quot;),
ON_QUEUE(4, &amp;quot;说明...&amp;quot;),
WAIT(6, &amp;quot;说明...&amp;quot;),
STOP(5, &amp;quot;说明...&amp;quot;),
ON_SUBMIT(7, &amp;quot;说明...&amp;quot;),,
WITH_RESULT(9, &amp;quot;说明...&amp;quot;),
FINISH(8, &amp;quot;说明...&amp;quot;),
DISPATCHED(10, &amp;quot;说明...&amp;quot;),

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;个人觉得有点问题，请各位看官分析&lt;/p&gt;

&lt;h2 id=&#34;有几个问题&#34;&gt;有几个问题&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;设计了一些不存在的状态，如finish状态，没有这个状态，结束态可以是成功、失败（里面包括人工kill掉），由方法来判断&lt;/li&gt;
&lt;li&gt;缺失了一些中间状态，如runing-&amp;gt;stop,缺失stoping状态&lt;/li&gt;
&lt;li&gt;stop状态换成killed状态语义更确切&lt;/li&gt;
&lt;li&gt;状态enum的value，设计混乱，没有业务语义&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Supervisor的正确玩法</title>
      <link>https://hanzhihua.cn/post/supervisor_1/</link>
      <pubDate>Tue, 27 Aug 2019 19:55:20 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/supervisor_1/</guid>
      
        <description>

&lt;p&gt;上次进程被莫名杀掉，为了避免同样错误的发生，现在我们统一接入supervisor，通过它来管理进程的启停&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;supervisor玩法有正确的玩法，也不正确的玩法（只有痛过才能真正体会）&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;不正确的玩法&#34;&gt;不正确的玩法&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;应用owner提供启动脚本（停止脚本一般是标配如kill -2 pid）&lt;/li&gt;
&lt;li&gt;运维同学安装supervisor,标准化目录结构&lt;/li&gt;
&lt;li&gt;运维同学提供supervisor配置文件&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;正确的玩法&#34;&gt;正确的玩法&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;应用owner提供启动脚本&lt;/li&gt;
&lt;li&gt;运维同学安装supervisor,标准化目录结构&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;应用owner提供supervisor配置文件&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;启动脚本例子&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
cp supervisor配置 /etc/supervisor/conf.d/
supervisorctl update
supervisorctl start 应用名
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;上面的脚本也可以写在发布系统中&lt;/li&gt;
&lt;li&gt;还有一种玩法就是发布系统只是负责应用的发布，不负责应用的启停，看官可以自选&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>采用snaphost版本</title>
      <link>https://hanzhihua.cn/post/mvn_1/</link>
      <pubDate>Mon, 26 Aug 2019 20:57:22 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/mvn_1/</guid>
      
        <description>

&lt;p&gt;因为是大数据部门，我们的应用基本上使用java语言开发，采用maven做项目管理&lt;br /&gt;
目前我们的项目版本都是snaphost的，线上发布也是这样的&lt;br /&gt;
本来想做一次整改，采用在线应用标准来要求，但发现效果并不好，会增加比较多的工作量&lt;br /&gt;
因为公司与之配套的工具平台缺失，公司项目主要以golang为主，对java支持的比较弱&lt;/p&gt;

&lt;h2 id=&#34;考虑数据平台项目的特点-我们内部达成一个共识&#34;&gt;考虑数据平台项目的特点，我们内部达成一个共识：&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;只使用snapshot版本，放弃release版本&lt;/li&gt;
&lt;li&gt;小功能开发，迭代不修改项目版本&lt;/li&gt;
&lt;li&gt;大功能修改或者对外接口变化才修改项目版本，仍采用snaphost版本&lt;/li&gt;
&lt;li&gt;版本回滚，依赖发布系统&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Nginx多次转发问题</title>
      <link>https://hanzhihua.cn/post/proxy_1/</link>
      <pubDate>Sat, 24 Aug 2019 18:49:06 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/proxy_1/</guid>
      
        <description>

&lt;p&gt;今天遇到一个nginx多次转发丢失客户端ip问题，原来的配置是这样的&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;proxy_set_header        X-Real-IP $remote_addr;
proxy_set_header        X-Forwarded-For $remote_addr;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;每一层nginx配置都是这样的，最后应用取得的客户端IP是上一层nginx的IP&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;根因是nginx的X-Real-IP被覆盖了&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;一般玩法&#34;&gt;一般玩法&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;可定义一个私有的变量 如 &lt;em&gt;x-backend-公司名-real-ip&lt;/em&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;第一层nginx&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;proxy_set_header        x-backend-公司名-real-ip $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;后面几层&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;应用方&lt;br /&gt;
通过x-backend-公司名-real-ip拿到客户端ip&lt;br /&gt;
通过X-Forwarded-For获得ip列表，(包括客户端IP、所有nginx的ip,通过逗号分隔，第一个为客户端IP）&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Mysql Exporter代码分析</title>
      <link>https://hanzhihua.cn/post/prom_1/</link>
      <pubDate>Sat, 24 Aug 2019 16:44:39 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/prom_1/</guid>
      
        <description>

&lt;p&gt;今天闲来无事看看 promthues的&lt;a href=&#34;https://github.com/prometheus/mysqld_exporter&#34;&gt;mysqlexporter&lt;/a&gt;
监控组件是如何实现的&lt;/p&gt;

&lt;h2 id=&#34;实现原理&#34;&gt;实现原理&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;遵循promethues的规范，提供http接口，返回标准的结果集&lt;/li&gt;

&lt;li&gt;&lt;p&gt;主要&lt;strong&gt;运行mysql命令采集指标&lt;/strong&gt;，包括以下指标，false默认不采集&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;var scrapers = map[collector.Scraper]bool{
	collector.ScrapeGlobalStatus{}:                        true,
	collector.ScrapeGlobalVariables{}:                     true,
	collector.ScrapeSlaveStatus{}:                         true,
	collector.ScrapeProcesslist{}:                         false,
	collector.ScrapeUser{}:                                false,
	collector.ScrapeTableSchema{}:                         false,
	collector.ScrapeInfoSchemaInnodbTablespaces{}:         false,
	collector.ScrapeInnodbMetrics{}:                       false,
	collector.ScrapeAutoIncrementColumns{}:                false,
	collector.ScrapeBinlogSize{}:                          false,
	collector.ScrapePerfTableIOWaits{}:                    false,
	collector.ScrapePerfIndexIOWaits{}:                    false,
	collector.ScrapePerfTableLockWaits{}:                  false,
	collector.ScrapePerfEventsStatements{}:                false,
	collector.ScrapePerfEventsStatementsSum{}:             false,
	collector.ScrapePerfEventsWaits{}:                     false,
	collector.ScrapePerfFileEvents{}:                      false,
	collector.ScrapePerfFileInstances{}:                   false,
	collector.ScrapePerfReplicationGroupMemberStats{}:     false,
	collector.ScrapePerfReplicationApplierStatsByWorker{}: false,
	collector.ScrapeUserStat{}:                            false,
	collector.ScrapeClientStat{}:                          false,
	collector.ScrapeTableStat{}:                           false,
	collector.ScrapeSchemaStat{}:                          false,
	collector.ScrapeInnodbCmp{}:                           true,
	collector.ScrapeInnodbCmpMem{}:                        true,
	collector.ScrapeQueryResponseTime{}:                   true,
	collector.ScrapeEngineTokudbStatus{}:                  false,
	collector.ScrapeEngineInnodbStatus{}:                  false,
	collector.ScrapeHeartbeat{}:                           false,
	collector.ScrapeSlaveHosts{}:                          false,
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;比如ScrapeGlobalStatus，就是运行 &lt;code&gt;SHOW GLOBAL STATUS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>写文件性能总结</title>
      <link>https://hanzhihua.cn/post/io_1/</link>
      <pubDate>Sat, 24 Aug 2019 10:56:11 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/io_1/</guid>
      
        <description>

&lt;p&gt;最近在项目中，看到一个已经离职同事写的关于写日志服务的代码&lt;/p&gt;

&lt;h1 id=&#34;写性能提升&#34;&gt;写性能提升&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;使用缓存，必要的时候在落盘&lt;/li&gt;
&lt;li&gt;预先定义文件大小，在生成文件生成一个长度固定的空文件&lt;/li&gt;

&lt;li&gt;&lt;p&gt;使用zero copy,可以是sendfile或者mmap方式,下面是mmap的例子&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;FileChannel fileChannel = new RandomAccessFile(this.file, &amp;quot;rw&amp;quot;).getChannel();
MappedByteBuffer mappedByteBuffer = fileChannel.map(MapMode.READ_WRITE, 0, 文件大小);
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>发布脚本问题</title>
      <link>https://hanzhihua.cn/post/shell_1/</link>
      <pubDate>Wed, 21 Aug 2019 20:51:15 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/shell_1/</guid>
      
        <description>

&lt;p&gt;今天一个应用系统在发布新版本过程中，发布系统在关闭应用的时候，随便也把其他应用关闭了&lt;/p&gt;

&lt;h1 id=&#34;背景&#34;&gt;背景&lt;/h1&gt;

&lt;p&gt;公司规模比较大，大部分项目是跑在k8s上面，部分项目是跑在kvm上面，但还有一些项目一个机器部署多个应用&lt;br /&gt;
而今天这个情况发生在部署一台机器上的多个应用&lt;/p&gt;

&lt;h1 id=&#34;问题根因&#34;&gt;问题根因&lt;/h1&gt;

&lt;p&gt;主要问题是出在stop脚本上面，下面是Stop脚本（看官，是不是觉得比较low吧，没有办法历史的原因）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/bin/bash                                                                                                                                                                                       
export JAVA_HOME=/usr/lib/jdk1.8.0
export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH
export CLASSPATH=$CLASSPATH:.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib

pid=$(ps -aux |grep 关键字|grep java| grep -v &amp;quot;grep&amp;quot;| awk &#39;{print $2}&#39;)

if [ -n &amp;quot;$pid&amp;quot; ];then
    kill -2 $pid
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;关键字是应用名，而这个应用是一个基础服务，会被很多其他应用依赖，所以pid会拿到多个应用进程的pid,
全部都kill 了&lt;/p&gt;

&lt;h1 id=&#34;解决方案&#34;&gt;解决方案&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;能容器化的，能虚拟化的，最好都部署在里面，不要直接部署在裸机上面&lt;/li&gt;
&lt;li&gt;关键字最好是启动类的全称，而不是应用名这样的缩写&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>负载均衡的问题</title>
      <link>https://hanzhihua.cn/post/lb_1/</link>
      <pubDate>Tue, 20 Aug 2019 20:00:11 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/lb_1/</guid>
      
        <description>

&lt;p&gt;最近线上出现一个故障，DAG系统调用hiveserver集群时，hiveserver集群有一个节点出现了crash
，造成了DAG系统出现大量错误&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;DAG系统维护hiveserver ip列表，使用smartclient方案来完成failover&lt;/li&gt;
&lt;li&gt;功能实现中有bug，造成了系统failover失败&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有同学提出意见，说无状态系统的高可用应该采用四层路由方式来保证&lt;/p&gt;

&lt;p&gt;&lt;em&gt;四层路由一般指haproxy、nginx tcp stream、lvs+keepalived&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;说说四层路由方式的优缺点&#34;&gt;说说四层路由方式的优缺点&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;优点&lt;br /&gt;
节点探活，自动上下线&lt;br /&gt;
支持多种负载均衡策略&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;缺点&lt;br /&gt;
节点探活只是在系统层面，无法做到应用层面&lt;br /&gt;
负载均衡策略也无法根据应用性能做出正确的判断&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;应用性能4个重要指标：延迟、错误率、吞吐、饱和度。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Jar包冲突问题</title>
      <link>https://hanzhihua.cn/post/jarconflict/</link>
      <pubDate>Fri, 16 Aug 2019 11:33:48 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/jarconflict/</guid>
      
        <description>

&lt;p&gt;今天发现了上线版本出现jar冲突问题&lt;/p&gt;

&lt;h2 id=&#34;jar包冲突&#34;&gt;jar包冲突&lt;/h2&gt;

&lt;p&gt;一般是下面两种情况&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;项目中依赖同一个jar的不同版本&lt;/li&gt;
&lt;li&gt;同一个class存在在不同的jar包中&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上述情况都会在运行中发生异常，造成麻烦&lt;/p&gt;

&lt;p&gt;可以加上&lt;a href=&#34;https://maven.apache.org/enforcer/maven-enforcer-plugin/&#34;&gt;enforcer&lt;/a&gt;插件，在项目打包时做检查&lt;/p&gt;

&lt;p&gt;加上这个&lt;a href=&#34;https://www.mojohaus.org/extra-enforcer-rules/banDuplicateClasses.html&#34;&gt;banDuplicateClasses规则&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;例子：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;build&amp;gt;
    &amp;lt;plugins&amp;gt;
      &amp;lt;plugin&amp;gt;
        &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;maven-enforcer-plugin&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;1.0&amp;lt;/version&amp;gt; &amp;lt;!-- find the latest version at http://maven.apache.org/plugins/maven-enforcer-plugin/ --&amp;gt;
        &amp;lt;executions&amp;gt;
          &amp;lt;execution&amp;gt;
            &amp;lt;id&amp;gt;default-cli&amp;lt;/id&amp;gt;
            &amp;lt;goals&amp;gt;
              &amp;lt;goal&amp;gt;enforce&amp;lt;/goal&amp;gt;
            &amp;lt;/goals&amp;gt;
            &amp;lt;configuration&amp;gt;
              &amp;lt;rules&amp;gt;
                &amp;lt;banDuplicateClasses&amp;gt;
                  &amp;lt;scopes&amp;gt;
                      &amp;lt;scope&amp;gt;compile&amp;lt;/scope&amp;gt;
                      &amp;lt;scope&amp;gt;provided&amp;lt;/scope&amp;gt;
                  &amp;lt;/scopes&amp;gt;
                  &amp;lt;findAllDuplicates&amp;gt;true&amp;lt;/findAllDuplicates&amp;gt;
                  &amp;lt;ignoreWhenIdentical&amp;gt;true&amp;lt;/ignoreWhenIdentical&amp;gt;
                &amp;lt;/banDuplicateClasses&amp;gt;
              &amp;lt;/rules&amp;gt;
              &amp;lt;fail&amp;gt;true&amp;lt;/fail&amp;gt;
            &amp;lt;/configuration&amp;gt;
          &amp;lt;/execution&amp;gt;
        &amp;lt;/executions&amp;gt;
        &amp;lt;dependencies&amp;gt;
          &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.codehaus.mojo&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;extra-enforcer-rules&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;1.2&amp;lt;/version&amp;gt;
          &amp;lt;/dependency&amp;gt;
        &amp;lt;/dependencies&amp;gt;
      &amp;lt;/plugin&amp;gt;
    &amp;lt;/plugins&amp;gt;
  &amp;lt;/build&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
      
    </item>
    
    <item>
      <title>hive语句太长问题</title>
      <link>https://hanzhihua.cn/post/dag_1/</link>
      <pubDate>Thu, 15 Aug 2019 20:30:17 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/dag_1/</guid>
      
        <description>&lt;p&gt;今天有一个同学写了一个超长的hive脚本， &amp;gt; 1000行，在执行ADHOC的时候出现错误&lt;/p&gt;

&lt;p&gt;分析原因，因为DAG系统的作业信息是存在mysql，作业的命令是text格式的，最大只有65535，超过mysql限制长度就
报错误了&lt;/p&gt;

&lt;p&gt;考虑到作业的命令是多条hql语句(以逗号分隔)，都比较长，后续将采用小文件方式来存放&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>使用消息中间件来均分任务</title>
      <link>https://hanzhihua.cn/post/mqtask/</link>
      <pubDate>Sun, 11 Aug 2019 15:04:12 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/mqtask/</guid>
      
        <description>

&lt;h2 id=&#34;业务场景&#34;&gt;业务场景&lt;/h2&gt;

&lt;p&gt;需要把一下大任务，均分到不同节点中去计算，利用集群规模来快速完成任务&lt;/p&gt;

&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;

&lt;p&gt;利用消息中间件的消息分配（任务分配）、容错、消费者（计算节点）的自动扩缩容，就可以非常简单的完成该功能。&lt;/p&gt;

&lt;p&gt;主要是利用rocketmq机制。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;建立topic，&lt;strong&gt;保证queue数量大于工作节点数量&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;由任务发起节点，把大任务拆分一个个小任务，发送到消息中间件&lt;/li&gt;
&lt;li&gt;各个任务处理节点按照分配对来处理小任务&lt;/li&gt;
&lt;li&gt;上报任务处理状态&lt;/li&gt;
&lt;/ul&gt;



&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/Snip20190812_219.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/Snip20190812_219.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;

</description>
      
    </item>
    
    <item>
      <title>服务进程管理脚本</title>
      <link>https://hanzhihua.cn/post/control_shell/</link>
      <pubDate>Sat, 10 Aug 2019 18:09:05 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/control_shell/</guid>
      
        <description>&lt;p&gt;在生成环境中，一般是使用&lt;a href=&#34;http://supervisord.org/&#34;&gt;supervisor&lt;/a&gt;来管理服务进程（运行在k8s平台上的服务，那就不需要了）&lt;/p&gt;

&lt;p&gt;但有的时候，我们可能采用简单的方式处理，对服务进程进行管理，就是简单的写一个control.sh&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;模板：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/bin/bash

WORK_DIR=$(cd $(dirname $0)/; pwd)
cd $WORK_DIR

SERVICE_NAME=服务名
PID_FILE=$SERVICE_NAME.pid
LOG_FILE=$SERVICE_NAME.out
SERVICE_CMD=服务启动脚本

function check_pid() {
if [ -f $PID_FILE ];then
    pid=`cat $PID_FILE`
    if [ -n $pid ]; then
        running=`ps -p $pid|grep -v &amp;quot;PID TTY&amp;quot; |wc -l`
        return $running
    fi
fi
return 0
}

function start() {
check_pid
running=$?
if [ $running -gt 0 ];then
    echo -n &amp;quot;$SERVICE_NAME now is running already, pid=&amp;quot;
    cat $PID_FILE
    return 1
fi

nohup $SERVICE_CMD   &amp;amp;&amp;gt; $LOG_FILE &amp;amp;
echo $! &amp;gt; $PID_FILE
echo &amp;quot;$SERVICE_NAME started..., pid=$!&amp;quot;
}

function stop() {
pid=`cat $PID_FILE`
kill $pid
echo &amp;quot;$SERVICE_NAME stoped...&amp;quot;
}

function restart() {
stop
sleep 1
start
}

function status() {
check_pid
running=$?
if [ $running -gt 0 ];then
    echo -n &amp;quot;$SERVICE_NAME now is running, pid=&amp;quot;
    cat $PID_FILE
else
    echo &amp;quot;$SERVICE_NAME is stoped&amp;quot;
fi
}

function tailf() {
tail -f $logfile
}

function help() {
echo &amp;quot;$0 start|stop|restart|status|tail&amp;quot;
}

if [ &amp;quot;$1&amp;quot; == &amp;quot;&amp;quot; ]; then
help
elif [ &amp;quot;$1&amp;quot; == &amp;quot;stop&amp;quot; ];then
stop
elif [ &amp;quot;$1&amp;quot; == &amp;quot;start&amp;quot; ];then
start
elif [ &amp;quot;$1&amp;quot; == &amp;quot;restart&amp;quot; ];then
restart
elif [ &amp;quot;$1&amp;quot; == &amp;quot;status&amp;quot; ];then
status
elif [ &amp;quot;$1&amp;quot; == &amp;quot;tail&amp;quot; ];then
tailf
else
help
fi
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>使用Goreplay来做压测</title>
      <link>https://hanzhihua.cn/post/goreplay1/</link>
      <pubDate>Fri, 09 Aug 2019 16:07:22 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/goreplay1/</guid>
      
        <description>

&lt;h1 id=&#34;背景&#34;&gt;背景&lt;/h1&gt;

&lt;p&gt;项目要做一个性能测试，希望能最大限度的模拟用户真实请求。&lt;/p&gt;

&lt;p&gt;项目特点弱安全性，无用户标识&lt;/p&gt;

&lt;h1 id=&#34;解决方案&#34;&gt;解决方案&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;使用&lt;a href=&#34;https://github.com/buger/goreplay&#34;&gt;goreplay&lt;/a&gt;来录制用户请求，来做压测样本&lt;/li&gt;
&lt;li&gt;登录线上服务器，录制请求&lt;br /&gt;
./gor &amp;ndash;input-raw :线上端口 &amp;ndash;output-file=input.gor &amp;ndash;output-file-append&lt;/li&gt;
&lt;li&gt;在压测机，放大流量压测&lt;br /&gt;
./gor &amp;ndash;input-file &amp;ldquo;input.gor|450000% &amp;ndash;output-http http://测试服务器IP:测试服务器port &amp;ndash;input-file-loop &amp;ndash;exit-after 60m&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>WEB端高可用默认玩法</title>
      <link>https://hanzhihua.cn/post/ha/</link>
      <pubDate>Thu, 08 Aug 2019 18:50:43 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/ha/</guid>
      
        <description>

&lt;h1 id=&#34;web服务高可用设计&#34;&gt;WEB服务高可用设计&lt;/h1&gt;

&lt;p&gt;主要是从以下几个方面去考虑，设计不考虑dns,动静态CDN&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;架构是slb+keepalived+web服务（针对运维高可用，需要做少量工作）&lt;/li&gt;
&lt;li&gt;slb开源可选方案lvs、haproxy、nginx&lt;/li&gt;
&lt;li&gt;slb是可以分层的,主要看项目规模&lt;/li&gt;
&lt;li&gt;高可用要需要跟CICD配合，web端需要做点工作&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;标准部署架构&#34;&gt;标准部署架构&lt;/h1&gt;



&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/Snip20190814_238.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/Snip20190814_238.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;h1 id=&#34;标准玩法&#34;&gt;标准玩法&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Nginx 配置&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;upstream api {
server *:8080 weight=5;
server *:8080 weight=5;
server *:8080 weight=5;
server *:8080 weight=5;
check interval=3000 rise=2 fall=3 timeout=1000 type=http;
check_http_send &amp;quot;HEAD /health/status HTTP/1.0\r\n\r\n&amp;quot;;
check_http_expect_alive http_2xx http_3xx;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;web端改造(java语言)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Controller
@RequestMapping(&amp;quot;/health&amp;quot;)
public class HealthController {

	private static boolean healthFlag = false;

	//白名单
	private static Set&amp;lt;String&amp;gt; ipSet = new HashSet&amp;lt;String&amp;gt;();

	static {
		ipSet.add(&amp;quot;******&amp;quot;);
	}

	//项目启动时触发 （由运维发布时触发）
	@RequestMapping(&amp;quot;/active&amp;quot;)
	public void active(HttpServletRequest request, HttpServletResponse response) {
		String ip = HttpUtils.getRemoteIP(request);
		if (ipSet.contains(ip)) {
			healthFlag = true;
		} else {
			response.setStatus(HttpServletResponse.SC_FORBIDDEN);
		}
	}

	//项目关闭时触发 由运维发布时触发）
	@RequestMapping(&amp;quot;/offline&amp;quot;)
	public void offline(HttpServletRequest request, HttpServletResponse response) {
		String ip = HttpUtils.getRemoteIP(request);
		if (ipSet.contains(ip)) {
			healthFlag = false;
		} else {
			response.setStatus(HttpServletResponse.SC_FORBIDDEN);
		}
	}
	
	//nginx来探测的URL，来判断web端是否上下线
	@RequestMapping(&amp;quot;/status&amp;quot;)
	public void status(HttpServletRequest request, HttpServletResponse response) {
		response.setStatus(healthFlag ? HttpServletResponse.SC_OK : HttpServletResponse.SC_FORBIDDEN);
	}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;发布流程流程&#34;&gt;发布流程流程&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;请求 /offline，在等待3-5s （nginx摘掉服务器和处理完已接受的请求）&lt;/li&gt;
&lt;li&gt;停应用&lt;/li&gt;
&lt;li&gt;发布，启动应用&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;请求 /active，挂到nginx上面，接受流量&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>血缘分析</title>
      <link>https://hanzhihua.cn/post/table_relate/</link>
      <pubDate>Thu, 08 Aug 2019 12:43:34 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/table_relate/</guid>
      
        <description>

&lt;p&gt;数据血缘就是分析数据之间的关系，是数据平台中元信息管理重要组成部分&lt;/p&gt;

&lt;p&gt;元信息是指数据平台中存储数据的元信息，就是各种类型表的元信息管理，一般包括 hive、hbase、mysql、ES、mongo、kafka(&lt;em&gt;topic及内部数据格式&lt;/em&gt;)&lt;/p&gt;

&lt;h1 id=&#34;概念&#34;&gt;概念：&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;表： hive表，BI报表。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;作业：对应一个sql文件，或者数据收集，数据转移任务，一个可以独立执行的程序；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;项目： DAG系统中概念，包含多个作业；&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;数据的血缘关系&#34;&gt;数据的血缘关系：&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;作业跟作业之间的血缘追溯&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;表跟作业之间的血缘追溯&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;表跟表之间的血缘追溯&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;字段级别的血缘追溯&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;功能图&#34;&gt;功能图&lt;/h1&gt;



&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/Snip20190808_213.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/Snip20190808_213.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;h1 id=&#34;怎么做&#34;&gt;怎么做&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;在DAG任务平台对sql语句、非sql（spark,MR）进行血缘挖掘&lt;/li&gt;
&lt;li&gt;DAG平台中，项目依赖关系&lt;/li&gt;
&lt;li&gt;对BI报表使用的数据源与DAG任务生成的数据源进行管理&lt;/li&gt;
&lt;li&gt;对存储引擎进行元信息同步&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;如何做&#34;&gt;如何做&lt;/h1&gt;

&lt;p&gt;TODO&amp;hellip;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>去zk网络分区容错方案</title>
      <link>https://hanzhihua.cn/post/zkchange/</link>
      <pubDate>Mon, 05 Aug 2019 20:32:50 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/zkchange/</guid>
      
        <description>

&lt;p&gt;最近在重构一个DAG系统，遇到一个组件节点通信、及节点发现的问题。&lt;/p&gt;

&lt;h1 id=&#34;原方案&#34;&gt;原方案&lt;/h1&gt;

&lt;p&gt;基本上就是传统的解决方案，服务发现、调用依赖zookeeper&lt;br /&gt;
部署图&lt;br /&gt;


&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/Snip20190805_207.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/Snip20190805_207.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;br /&gt;
这个方案，有一个致命问题就是当执行节点与zk出现网络不稳定时，会造成控制节点做出错误的决定&lt;br /&gt;
这个时候也许控制节点与执行节点的通信是非常正常，这就是典型的网络分区问题&lt;br /&gt;
考虑到 控制节点与执行节点之间的通信还是主要，而与zk的通信就不是那么的重要，所以减少对zk的依赖，
只处理zk的节点上线通知，对于下线通知就不处理了，改成依赖节点间的心跳&lt;/p&gt;

&lt;h1 id=&#34;新方案&#34;&gt;新方案&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;只侦听zk的节点新增通知，忽略节点下线的通知&lt;/li&gt;
&lt;li&gt;在执行节点与通信节点新增心跳&lt;/li&gt;
&lt;li&gt;节点下线，由心跳超时来确定&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/Snip20190805_210.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/Snip20190805_210.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;h1 id=&#34;附加知识点&#34;&gt;附加知识点&lt;/h1&gt;

&lt;p&gt;在开发节点心跳功能时，需要对网络timeout类型完全理解。&lt;/p&gt;

&lt;p&gt;案例分析，出现下面异常：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;2019-08-02 18:44:59.476 controlnode [nioEventLoopGroup-2-1] c.b.a.c.j.i.net.NettyChannelClient.exceptionCaught ERROR - error while pipeline: {}
java.io.IOException: Operation timed out
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:311)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:881)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:241)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;很多同学会认为是应用层中设置的connectiontimeout,或者sotimeout,其实&lt;strong&gt;可能&lt;/strong&gt;都不是&lt;br /&gt;
而是TCP层 &lt;strong&gt;报文失败重传 timeout&lt;/strong&gt;&lt;br /&gt;
可以使用tcpdump来查看就明白了&lt;br /&gt;
TCP层会对报文重传，分超时重传、快速重传，如果当重传报文多次没有收到ack，kernel会reset连接,对应应用层就收到了上述的异常&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>
