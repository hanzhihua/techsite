<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>一个码农 工作点滴</title>
    <link>https://hanzhihua.cn/</link>
    <description>Recent content on 一个码农 工作点滴</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>All rights reserved - 2019 沪ICP备19026538号 </copyright>
    <lastBuildDate>Tue, 22 Oct 2019 13:03:07 +0800</lastBuildDate>
    
        <atom:link href="https://hanzhihua.cn/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>线上一个小故障</title>
      <link>https://hanzhihua.cn/post/cs_3/</link>
      <pubDate>Tue, 22 Oct 2019 13:03:07 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/cs_3/</guid>
      
        <description>

&lt;p&gt;昨天线上运行的调度系统，又出了一个故障&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;p&gt;因为跟业务强相关，这个忽略&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;p&gt;主要原因就是一个很重要的线程莫名其妙的消失了，下面是该线程的runnalbe的伪代码&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void run(){
                try{
                    业务逻辑
                }catch(Exception e){
                    异常处理   
                }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一般如果直接实现Runnalbe,这个算是标配&lt;br /&gt;
跟踪日志，并没有发现错误日志的出现，开始怀疑应该是有Error,或者Throwable的这样的错误&lt;br /&gt;
突然发现业务逻辑中有这样的代码片段&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;assert  channel != null;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;又发现启动程序中JVM已经使用了 -ea参数，问题找到了，就是assert抛出了Error造成的&lt;/p&gt;

&lt;p&gt;再度分析，为什么channel会为空（当前NIO框架是Netty）,后来发现代码中Overrider了下面两个方法&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void channelActive(ChannelHandlerContext ctx) throws Exception
public void channelInactive(ChannelHandlerContext ctx) throws Exception 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;根因找到了，因为这个两个事件触发的顺序问题，造成了channal为空&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;记住：当发生channal快速重连的情况，上述两个方法不能保证的触发顺序&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这次异常就是因为channelActive事件先于channelInactive事件触发&lt;/p&gt;

&lt;h2 id=&#34;改善措施&#34;&gt;改善措施&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;放弃使用java assert断言，使用其他第三方的断言处理方案，目前采用Guava的Preconditions&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;放弃把业务逻辑放在netty事件里处理，也放弃Netty，准备自己重新实现NIO框架，这样可控&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>RPC协议设计</title>
      <link>https://hanzhihua.cn/post/rpc_pro_1/</link>
      <pubDate>Sat, 19 Oct 2019 13:27:58 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/rpc_pro_1/</guid>
      
        <description>

&lt;p&gt;NIO框架、RPC服务都需要设计私有通信协议，包括协议头+协议体&lt;/p&gt;

&lt;h3 id=&#34;协议头&#34;&gt;协议头&lt;/h3&gt;

&lt;p&gt;一般包括：MagicCode+协议版本+请求类型(req/reps/oneway)+保留字段（特殊字段）+报文头长度+报文体长度+RequestID+序列化类型&lt;/p&gt;

&lt;p&gt;协议头长度一般是固定的，一般包含一些不需要做反序列化就可以读的特殊字段&lt;/p&gt;

&lt;h3 id=&#34;协议体&#34;&gt;协议体&lt;/h3&gt;

&lt;p&gt;一般就是序列化Byte数组，可以是PB序列化，或者Hessian序列化等&lt;/p&gt;

&lt;h2 id=&#34;encoder-decoder&#34;&gt;encoder/decoder&lt;/h2&gt;

&lt;p&gt;NIO框架一般是需要Bytebuf这种数据结构，需要支持increase，descrease功能&lt;/p&gt;

&lt;h2 id=&#34;读操作-decoder&#34;&gt;读操作（decoder）&lt;/h2&gt;

&lt;p&gt;读操作一般流程是&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;flip（转成读模式）&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;decode(解码)&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;compact （删除读过的字节）&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;读协议体&#34;&gt;读协议体&lt;/h3&gt;

&lt;p&gt;流程一般是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;判断buffer可用长度是否大于协议头长度，如果不满足等待下一次读&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;检查MagicCode&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;读协议体-1&#34;&gt;读协议体&lt;/h3&gt;

&lt;p&gt;流程一般是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;判断buffer可用长度是否大于报文体长度，如果不满足等待下一次读&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;根据序列化类型，做反序列化形成对象&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;写操作-encoder&#34;&gt;写操作(encoder)&lt;/h2&gt;

&lt;p&gt;流程一般是：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;准备需要传送的对象&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;序列化对象，形成字节数组&lt;/li&gt;
&lt;li&gt;生成一个bytebuffer，设置头信息&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;设置Body信息&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;发送：）&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>hive/spark server-jdbc连接池问题</title>
      <link>https://hanzhihua.cn/post/cpool_1/</link>
      <pubDate>Fri, 11 Oct 2019 16:38:07 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/cpool_1/</guid>
      
        <description>

&lt;p&gt;&lt;strong&gt;昨天线上DAG系统出现了连接池的问题&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;p&gt;昨天部分服务器做内存扩容，这些服务器上面跑着包括*hivethrift/sparkthrift server*等服务&lt;/p&gt;

&lt;p&gt;用户在adhoc操作时出现异常&lt;/p&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;p&gt;用户的adhoc操作走的是jdbc协议，而数据库服务器的节点配置是在上面的服务器上随机了配置三台服务器&lt;/p&gt;

&lt;p&gt;执行节点使用了durid连接池，随机在三台服务器找一台作为数据库服务器来建立并维护连接&lt;/p&gt;

&lt;p&gt;如果这个时候该服务器重启，那么就会发生org.springframework.jdbc.CannotGetJdbcConnectionException 异常，&lt;/p&gt;

&lt;p&gt;并且在服务器没有重启完成时不能自愈&lt;/p&gt;

&lt;p&gt;&lt;em&gt;为什么采取jdbc方式，主要是利用连接池中的长连接，以提高adhoc 检测/执行的性能&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;改善措施&#34;&gt;改善措施&lt;/h2&gt;

&lt;p&gt;不大改，采用简单处理方式，如果后续再出现org.springframework.jdbc.CannotGetJdbcConnectionException 异常时，&lt;/p&gt;

&lt;p&gt;可以推断出改hivethrift/springthrift server重启了&lt;/p&gt;

&lt;p&gt;处理方式：&lt;strong&gt;剔除该节点，在列表中重新选择其他的一个节点建立连接池&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;其他&#34;&gt;其他&lt;/h2&gt;

&lt;p&gt;如果hiveserver对比mysqlserver,数据库节点出现问题，一般使用以下方式处理&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;没有采用DNS的应用，一般是应用修改配置，重启应用来解决&lt;/li&gt;
&lt;li&gt;采用DNS的应用，运维手动修改DNS配置，并清除DNS缓存来完成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;两个都比较耗时的&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>IO模型比较</title>
      <link>https://hanzhihua.cn/post/io_2/</link>
      <pubDate>Wed, 09 Oct 2019 13:01:30 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/io_2/</guid>
      
        <description>

&lt;h2 id=&#34;io模型&#34;&gt;IO模型&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;IO请求划分两个阶段：

&lt;ul&gt;
&lt;li&gt;等待数据就绪&lt;/li&gt;
&lt;li&gt;从内核缓冲区(socket send/receive buffer)拷贝到进程内存中&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;安全请求是否堵塞

&lt;ul&gt;
&lt;li&gt;同步IO&lt;/li&gt;
&lt;li&gt;异步IO&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Unix的几种IO模型

&lt;ul&gt;
&lt;li&gt;阻塞IO （BIO）&lt;/li&gt;
&lt;li&gt;IO复用  (NIO)&lt;/li&gt;
&lt;li&gt;异步IO  (AIO)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;io模型之间的区别&#34;&gt;IO模型之间的区别&lt;/h2&gt;



&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/io_c.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/io_c.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;h2 id=&#34;io策略&#34;&gt;IO策略&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;BIO:每个client一个线程&lt;/li&gt;
&lt;li&gt;NIO:单线程，多个client,非阻塞（IO复用）

&lt;ul&gt;
&lt;li&gt;水平触发&lt;/li&gt;
&lt;li&gt;边缘触发&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;AIO: 单线程，多个client&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;nio-aio比较&#34;&gt;NIO,AIO比较&lt;/h2&gt;

&lt;p&gt;NIO通过一个selectdor(注册器)来最轮询监听连接和读取数据，内核依赖epoll来实现
需要写代码来实现轮询，一般是利用nio框架
AIO不需要selector这样东西，有内核来实现，数据准备完成后来通知应用
不需要更多的代码&lt;/p&gt;

&lt;h3 id=&#34;aio实现&#34;&gt;AIO实现&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Windows: IOCP&lt;/li&gt;
&lt;li&gt;Linux: epoll模拟
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>安全相关</title>
      <link>https://hanzhihua.cn/post/sec_1/</link>
      <pubDate>Sun, 06 Oct 2019 10:25:14 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/sec_1/</guid>
      
        <description>

&lt;h1 id=&#34;安全分类&#34;&gt;安全分类&lt;/h1&gt;

&lt;h2 id=&#34;waf相关&#34;&gt;WAF相关&lt;/h2&gt;

&lt;p&gt;Web APP 防火墙：恶意攻击拦截、拦截数据分析、限制 API 访问频率等&lt;/p&gt;

&lt;h3 id=&#34;流量访问频率限制&#34;&gt;流量访问频率限制&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;IP 访问频率限制&amp;amp;封禁&lt;/li&gt;
&lt;li&gt;Session 访问频率限制&amp;amp;封禁&lt;/li&gt;
&lt;li&gt;默认无频率限制，需对域名或URL进行配置&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;主机入侵检测系统&#34;&gt;主机入侵检测系统&lt;/h2&gt;

&lt;p&gt;安装部署、问题跟进、主机安全相关&lt;/p&gt;

&lt;h2 id=&#34;业务风控&#34;&gt;业务风控&lt;/h2&gt;

&lt;p&gt;帐号体系、内容体系、高频业务流量等&lt;/p&gt;

&lt;h2 id=&#34;网络准入&#34;&gt;网络准入&lt;/h2&gt;

&lt;p&gt;公司办公楼网络安全准入控制相关问题&lt;/p&gt;

&lt;h2 id=&#34;数据安全&#34;&gt;数据安全&lt;/h2&gt;

&lt;p&gt;加密传输、数据脱敏、数据销毁、DLP、数据加密、数据使用规范等&lt;/p&gt;

&lt;h2 id=&#34;舆情监控&#34;&gt;舆情监控&lt;/h2&gt;

&lt;p&gt;监控 Github&amp;amp;Gitlab 代码泄露、微博发表安全相关言论监控等&lt;/p&gt;

&lt;h1 id=&#34;最佳实践&#34;&gt;最佳实践&lt;/h1&gt;

&lt;h2 id=&#34;生产网络安全&#34;&gt;生产网络安全&lt;/h2&gt;

&lt;h3 id=&#34;ddos&#34;&gt;DDOS&lt;/h3&gt;

&lt;h3 id=&#34;系统后门告警排查&#34;&gt;系统后门告警排查&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;排查方向&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;挖矿程序 服务器CPU资源使用情况&lt;/li&gt;
&lt;li&gt;DDOS木马 服务器出流量情况
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可疑文件创建时间，以此时间排查其他文件是否有改动：stat filename（modify与change时间相差过大以change时间为主）&lt;/p&gt;

&lt;p&gt;可疑文件句柄：lsof&lt;/p&gt;

&lt;p&gt;可疑进程运行权限：ps（排查相应权限运行的 服务/应用 是否存在漏洞等）&lt;/p&gt;

&lt;p&gt;命令是否被篡改： ps/ls/netstat/ss/top 等命令（排查命令文件修改时间/md5、ls -alt &amp;ndash;sort=time /bin/）&lt;/p&gt;

&lt;p&gt;服务器登录记录：auth.log/secure/sshd.log、last&lt;/p&gt;

&lt;p&gt;cron任务排查：/etc/cron*、/var/spool/cron&lt;/p&gt;

&lt;p&gt;可疑用户：/etc/passwd&lt;/p&gt;

&lt;p&gt;SSH 公钥：/root/.ssh/authorized_keys（文件是否有改动）&lt;/p&gt;

&lt;p&gt;SSH 配置：/etc/ssh/sshd_config（文件是否有改动、是否运行密码登录）&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;主机安全&#34;&gt;主机安全&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;账号排查

&lt;ul&gt;
&lt;li&gt;启用账号列表：root，ansible&lt;/li&gt;
&lt;li&gt;是否支持使用密码登录主机：root 允许key和密码登录，但无弱口令情况&lt;/li&gt;
&lt;li&gt;系统内各个账号的公钥是否异常：否&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;端口排查

&lt;ul&gt;
&lt;li&gt;端口监听程序是否为已知程序&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;进程排查

&lt;ul&gt;
&lt;li&gt;是否为已知业务的正常进&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;操作审计

&lt;ul&gt;
&lt;li&gt;近期内可疑的命令行操作记录：30 天内未发现敏感操作&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;入侵检测

&lt;ul&gt;
&lt;li&gt;是否部署主机入侵检测系统&lt;/li&gt;
&lt;li&gt;是否支持 BASH 安全审计&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;定时任务

&lt;ul&gt;
&lt;li&gt;排查未发现可疑定时任务&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;外网端口访问:&lt;/li&gt;
&lt;li&gt;标准进程和标准端口&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;弱口令修复方案&#34;&gt;弱口令修复方案&lt;/h3&gt;

&lt;p&gt;弱口令主要包含 SSH、MySQL、Redis、rsync、ftp等服务。&lt;/p&gt;

&lt;h2 id=&#34;安全规范&#34;&gt;安全规范&lt;/h2&gt;

&lt;h3 id=&#34;数据安全-1&#34;&gt;数据安全&lt;/h3&gt;

&lt;h3 id=&#34;网络安全规范&#34;&gt;网络安全规范&lt;/h3&gt;

&lt;h4 id=&#34;全站-https-整改计划&#34;&gt;全站 HTTPS 整改计划&lt;/h4&gt;

&lt;p&gt;HTTPS 在 HTTP 的基础上增加了SSL/TLS加密，提供了更加安全的传输协议，全站 HTTPS 可以有效的防止运营商劫持、中间人攻击。
另外，对于外部接入的第三方应用，严格要求统一使用 HTTPS 安全传输协议。&lt;/p&gt;

&lt;p&gt;整改流程：
服务端是否支持 HTTPS 协议
前段是否存在写死的 HTTP 协议
客户端是否存在写死的 HTTP 协议
增加 HTTP 到 HTTPS的 301 跳转&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Raft简介</title>
      <link>https://hanzhihua.cn/post/raft_2/</link>
      <pubDate>Sat, 05 Oct 2019 23:26:57 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/raft_2/</guid>
      
        <description>

&lt;h2 id=&#34;什么是raft协议&#34;&gt;什么是Raft协议&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;一致性算法&lt;/li&gt;
&lt;li&gt;解决分布式系统多副本的一致性&lt;/li&gt;
&lt;li&gt;集群高可用（在部分节点不工作时）&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;状态机&#34;&gt;状态机&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;响应外部请求的&lt;/li&gt;
&lt;li&gt;管理内部的状态&lt;/li&gt;
&lt;li&gt;例子：Memcache、redis


&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_sm.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_sm.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;复制状态机&#34;&gt;复制状态机&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;日志复制确保各个节点状态机执行相同的命令及相同的顺序&lt;/li&gt;
&lt;li&gt;一致性模块确保日志正确的复制&lt;/li&gt;
&lt;li&gt;在大部分机器存活时，系统能正常工作，&lt;/li&gt;
&lt;li&gt;故障模型：丢消息、消息验收，fail-stop，不会产生随机故障（Byzantine）


&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_rp_sm.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_rp_sm.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;raft分解&#34;&gt;Raft分解&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Leader选举

&lt;ul&gt;
&lt;li&gt;只有一个节点可以做为Leader&lt;/li&gt;
&lt;li&gt;侦测crashes, 选择新的Leader&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;日志复制

&lt;ul&gt;
&lt;li&gt;Leader接受Client请求，转成日志&lt;/li&gt;
&lt;li&gt;Leader复制日志到其他的节点&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;安全性

&lt;ul&gt;
&lt;li&gt;日志的一致性&lt;/li&gt;
&lt;li&gt;只有拥有最新的日志的节点才可以成为Leader&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;节点状态和rpc&#34;&gt;节点状态和RPC&lt;/h2&gt;



&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_s_rpc.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_s_rpc.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;h2 id=&#34;terms&#34;&gt;Terms&lt;/h2&gt;



&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_term.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_term.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;每一个term最多只有一个leader&lt;/li&gt;
&lt;li&gt;有的term没有leader（选举失败）&lt;/li&gt;
&lt;li&gt;每个节点维护自己的term

&lt;ul&gt;
&lt;li&gt;在每次rpc过程中交换&lt;/li&gt;
&lt;li&gt;Peer有更大的term,setpdown成为follower&lt;/li&gt;
&lt;li&gt;请求包含无效的term，就丢弃&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;leader选举&#34;&gt;Leader选举&lt;/h2&gt;



&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_l_ele.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_l_ele.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;h2 id=&#34;选举的正确性&#34;&gt;选举的正确性&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;安全性：允许每个term最多一个winner

&lt;ul&gt;
&lt;li&gt;每个节点每个term只能头一次票&lt;/li&gt;
&lt;li&gt;获得大多数票才能赢得选举&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Liveness：要有一个Candidate获得选举

&lt;ul&gt;
&lt;li&gt;选举超时时间是随机在[T,2T]&lt;/li&gt;
&lt;li&gt;一个节点可以依赖timeout来赢得选举&lt;/li&gt;
&lt;li&gt;T &amp;gt;&amp;gt; 广播时间&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;随机timeout方法比Ranking方法简单&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;操作流程&#34;&gt;操作流程&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Client 发送命令到Leader&lt;/li&gt;
&lt;li&gt;Leader 把命令 append到它的log中&lt;/li&gt;
&lt;li&gt;Leader 发送 AppendEntries RPCs 给所有的followers&lt;/li&gt;
&lt;li&gt;一旦命令 提交：

&lt;ul&gt;
&lt;li&gt;Leader 在它的状态机中执行命令，返回结果给Client&lt;/li&gt;
&lt;li&gt;Leader 在下一次AppendEntriesRPS通知followers，提交命令&lt;/li&gt;
&lt;li&gt;Followers在它的状态机中执行命令&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Crashed/slow followers

&lt;ul&gt;
&lt;li&gt;Leader 重试 AppendEntries RPCs 直到它们成功
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;日志结构&#34;&gt;日志结构&lt;/h2&gt;

&lt;p&gt;

&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_l_s.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_l_s.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;

* 当节点crash时，日志必须保存（需要落盘）
* Committed的entry必须被状态机执行过
   * 当日志存在多个节点上（被复制）&lt;/p&gt;

&lt;h2 id=&#34;日志不一致性&#34;&gt;日志不一致性&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;节点crash造成了日志的不一致性


&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_l_i.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_l_i.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;Raft修复日志不一致方法

&lt;ul&gt;
&lt;li&gt;Leader的日志是正确的&lt;/li&gt;
&lt;li&gt;Leader会帮助follower使用修复日志&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;日志匹配特征&#34;&gt;日志匹配特征&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;如果日志记录在不同节点有相同的index和term

&lt;ul&gt;
&lt;li&gt;他们存储相同的命令&lt;/li&gt;
&lt;li&gt;之前的日志记录也是完全相同的


&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_l_m.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_l_m.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如果一个日志记录被Committed过，那么所有之前的日志记录都被Committed&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;appendentries-一致性检查&#34;&gt;AppendEntries 一致性检查&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;AppendEntries RPCs 包含当前日志及前一个日志&lt;index,term&gt;&lt;/li&gt;
&lt;li&gt;Follower需要匹配前一个的日志的，否则将拒绝请求

&lt;ul&gt;
&lt;li&gt;Leader 使用前一个日志重试&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;实现，需要满足日志匹配特征


&lt;div class=&#34;box&#34;&gt;
&lt;figure  itemprop=&#34;associatedMedia&#34;
  itemscope itemtype=&#34;http://schema.org/ImageObject&#34; &gt;
    &lt;div class=&#34;img&#34;&gt;
      &lt;img itemprop=&#34;thumbnail&#34; src=&#34;https://hanzhihua.cn/raft_l_c.png&#34; /&gt;
    &lt;/div&gt;
    &lt;a href=&#34;https://hanzhihua.cn/raft_l_c.png&#34; itemprop=&#34;contentUrl&#34;&gt;&lt;/a&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;安全性-leader完整性&#34;&gt;安全性：Leader完整性&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;一旦日志记录committed,后面的Leader必须存储这个日志记录&lt;/li&gt;
&lt;li&gt;节点包含没有完成的日志记录不能赢得选举

&lt;ul&gt;
&lt;li&gt;Candidate包含最后日志记录&lt;/li&gt;
&lt;li&gt;Voting 服务器拒绝投票，如果它的日志是更新&lt;/li&gt;
&lt;li&gt;日志排序根据最后的term和index&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>线上死锁问题分析</title>
      <link>https://hanzhihua.cn/post/dl_1/</link>
      <pubDate>Sun, 29 Sep 2019 14:13:34 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/dl_1/</guid>
      
        <description>

&lt;p&gt;最近线上DAG系统居然出现了死锁问题&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;p&gt;DAG系统新版本发布，系统启动过程中在获取连接时出现了hang住的现象&lt;/p&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;DAG系统包括两个组件（控制节点和工作节点），控制节点在接受用户请求或者启动时都会主动连接工作节点&lt;br /&gt;
连接过程中，包括一个session建立的初始化请求（类似于zookeeper 客户端连接服务），session init后连接工作才算完成&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;过程中两把锁，一个是连接建立是需要的socket锁和一个是节点track是需要的session锁&lt;/li&gt;
&lt;li&gt;代码中使用了jvm锁机制，使用了synchronized 关键字&lt;/li&gt;
&lt;li&gt;系统启动时，需要节点track初始化session，需要获得session锁，而同时又需要接受用户请求需要初始化连接,使用的是socket锁&lt;/li&gt;
&lt;li&gt;节点track需要初始化连接，需要socket锁&lt;/li&gt;
&lt;li&gt;初始化连接又需要初始化session，需要session锁&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;尽量避免锁的嵌套&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;session,socket两把锁在业务语义上是一样的，可以直接修改成一把锁&lt;/li&gt;
&lt;li&gt;也可以用concurrent包lock对象，利用超时机制避免死锁出现&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>个人搭建VPN代理</title>
      <link>https://hanzhihua.cn/post/ss_1/</link>
      <pubDate>Wed, 18 Sep 2019 14:00:34 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/ss_1/</guid>
      
        <description>

&lt;p&gt;作为一个技术人员，不能上google的话，工作效率会下降很多，所以我们需要一个VPN&lt;br /&gt;
可以通过购买VPN服务，或者自行搭建VPN服务&lt;br /&gt;
因为购买的VPN服务经常会被墙，所以选择自行搭建VPN服务，缺点：最好只上Google,其他需要考虑流量成本&lt;/p&gt;

&lt;h2 id=&#34;搭建vpn方法&#34;&gt;搭建VPN方法&lt;/h2&gt;

&lt;h3 id=&#34;申请aws-免费空间&#34;&gt;申请AWS 免费空间&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;选择Amazon EC2免费套餐(1年内免费)，实例类型 t2.micro，可以选择东京或者韩国地区&lt;/li&gt;
&lt;li&gt;下载pem文件，需要通过它来做ssh登录，命令 &lt;code&gt;ssh -i &amp;quot;***.pem&amp;quot; ec2-user@****.compute.amazonaws.com&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;在安全组中加上一个自定义 TCP 规则，配置你的VPN端口&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;vpn-软件安装&#34;&gt;VPN 软件安装&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;软件选择 &lt;a href=&#34;https://github.com/shadowsocks/go-shadowsocks2&#34;&gt;go-shadowsocks2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;可直接下载已经编译完成的包，如果了解golang,可自行编译&lt;/li&gt;
&lt;li&gt;启动软件 &lt;code&gt;shadowsocks2 -s &#39;ss://AES-128-CFB:你的密码@[]:你的端口&#39; -verbose&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;安装ss 客户端即可&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>JAVA 处理信号</title>
      <link>https://hanzhihua.cn/post/sig_1/</link>
      <pubDate>Sat, 14 Sep 2019 17:27:28 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/sig_1/</guid>
      
        <description>

&lt;h2 id=&#34;信号&#34;&gt;信号&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;在终端查看所有的信号，可以通过 &lt;code&gt;kill -l&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;给指定进程发送信号，&lt;code&gt;kill -s ** pid&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;详情 &lt;code&gt;man kill&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;java中处理信号方法&#34;&gt;java中处理信号方法&lt;/h2&gt;

&lt;h3 id=&#34;注册信号&#34;&gt;注册信号&lt;/h3&gt;

&lt;p&gt;需要预先判断rt.jar中是否包含sun.misc.Signal&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;try {
            Class.forName(&amp;quot;sun.misc.Signal&amp;quot;);
        } catch (final Throwable t) {
            if (LOG.isWarnEnabled()) {
                LOG.warn(&amp;quot;sun.misc.Signal: unavailable, {}.&amp;quot;, t);
            }
            return;
        }
final sun.misc.Signal signal = new sun.misc.Signal(signalName);
final sun.misc.SignalHandler handler = ...;
sun.misc.Signal.handle(signal, handler);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;处理信号&#34;&gt;处理信号&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;实现 sun.misc.SignalHandler接口 即可&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>线上zookeeper使用中的一个坑</title>
      <link>https://hanzhihua.cn/post/zk_3/</link>
      <pubDate>Thu, 12 Sep 2019 19:21:33 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/zk_3/</guid>
      
        <description>

&lt;p&gt;线上DAG又出现BUG了，这个系统BUG还真多&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;DAG系统的执行节点重启发布&lt;/li&gt;
&lt;li&gt;正常流程 执行节点stop，自动摘掉zookeeper上面的EPHEMERAL节点，执行节点start，再重新挂上zookeeper EPHEMERAL节点，接受控制节点的调度。&lt;/li&gt;
&lt;li&gt;但这次发布过程中stop流程耗时比较长，最后发布系统采用kill -9 方式结束进程&lt;/li&gt;
&lt;li&gt;start流程正常启动，zookeeper 节点正常挂上&lt;/li&gt;
&lt;li&gt;但该zookeeper节点会莫名消失，而应用却是一切正常的，所以该执行节点无法被控制节点发现，也就无法正常工作&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;问题找到了，主要出现在挂节点流程中，代码如下:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private void registerExecuteNode() throws Exception {
    // 启动 重试
    int retryTimes = 0;
    do {
        retryTimes++;
        upsertExecuteZNode(convert(currentNode));
        LOGGER.info(&amp;quot;register execute node {} tries&amp;quot;, retryTimes);
    } while (zNodeDao.getExecuteZNode(currentNode.getId()) == null &amp;amp;&amp;amp; retryTimes &amp;lt; REGISTER_RETRY_COUNTS);
    if (zNodeDao.getExecuteZNode(currentNode.getId()) == null) {
        throw new RegisterFailedException(&amp;quot;register execute node error&amp;quot;);
    }
}
public void upsertExecuteZNode(ExecuteZNode executeZNode) throws Exception {

    try {
        String path = ...;
        zkClientTemplate.writeData(path, false, serialization(executeZNode)); //问题出现在这里
    } catch (Exception e) {
        LOGGER.error(&amp;quot;create or update execute znode error {}&amp;quot;, BilibiliSerializeUtils.toJSON(executeZNode), e);
        throw e;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;问题主要出现在zkClientTemplate.writeData，该方法会检查path是否存在，如果存在，那么就更新该节点内容。&lt;/p&gt;

&lt;p&gt;因为进程是被kill -9 强制关闭的，那么zookeeper上的节点就可能是由被kill的进程建立，新进程只是简单的更新了改节点的内容，而这个节点会因为zookeeper的session过期被zookeeper移除&lt;/p&gt;

&lt;h2 id=&#34;修复&#34;&gt;修复&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;应用启动时，先检查zookeeper是否有该节点，如果有，就先删除，然后重新建立新的节点&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;zookeeper的坑&#34;&gt;zookeeper的坑&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;zookeeper的EPHEMERAL的节点是有过期时间的，如果进程没有正确的告知zookeeper删除该节点（主要是正常的执行完成zookeepr.close 方法）
那么该节点不会因为进程的消失而马上消失&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>hiveserver2重启后的BUG</title>
      <link>https://hanzhihua.cn/post/hive_bug1/</link>
      <pubDate>Wed, 11 Sep 2019 14:22:59 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/hive_bug1/</guid>
      
        <description>

&lt;p&gt;昨天晚上，hiveserver2重启发布了，线上DAG系统查询hive时出现大量的broken pipe错误&lt;/p&gt;

&lt;p&gt;DAG系统使用了jdbc连接池方式来访问hiveserver2，感觉使用了无效的连接，而这些无效的连接一直保留在连接池中，不能被回收&lt;/p&gt;

&lt;h2 id=&#34;问题分析&#34;&gt;问题分析&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;jdbc协议使用了连接池，利用第三方连接池(druid)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;配置如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jdbc.driver=org.apache.hive.jdbc.HiveDriver
jdbc.url=***
jdbc.user=***
jdbc.pwd=***
jdbc.initialSize=16
jdbc.maxActive=64
jdbc.maxIdle=60000
jdbc.maxWait=10000
jdbc.eviction_interval = 60000L
jdbc.testOnBorrow = false
jdbc.testOnReturn = false
jdbc.testWhileIdle = true
jdbc.validation_query  = &amp;quot;select 1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;配置说明&#34;&gt;配置说明&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;连接池中的连接只有在空闲的时候做检查，如果该连接一直在使用，则不做检查，空闲时间超过(eviction_interval) 60s则会做连接检查&lt;/li&gt;
&lt;li&gt;检查语句为 &amp;ldquo;select 1&amp;rdquo;&lt;/li&gt;
&lt;li&gt;说明一个问题，如果hiveserver2重启后，如果1分钟内没有进行adhoc查询，那么什么事情也不会发生，你好我好，1分钟后所有坏的连接都被回收,重新建立&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;很不巧，昨天我们的thriftserver2重启后，不停的有人来访问，搞的大家紧张兮兮&lt;/p&gt;

&lt;p&gt;另外连接池有一个非常重要的东西是*ExceptionSorter*，它会根据SQLException中的errorCode来判断是否要真正的关闭连接。
我们选择的是Druid连接池，它的逻辑如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; for (Class&amp;lt;?&amp;gt; driverClass = driver.getClass();;) {
            String realDriverClassName = driverClass.getName();
            if (realDriverClassName.equals(JdbcConstants.MYSQL_DRIVER) //
                    || realDriverClassName.equals(JdbcConstants.MYSQL_DRIVER_6)) {
                this.exceptionSorter = new MySqlExceptionSorter();
                this.isMySql = true;
            } else if (realDriverClassName.equals(JdbcConstants.ORACLE_DRIVER)
                    || realDriverClassName.equals(JdbcConstants.ORACLE_DRIVER2)) {
                this.exceptionSorter = new OracleExceptionSorter();
            } else if (realDriverClassName.equals(&amp;quot;com.informix.jdbc.IfxDriver&amp;quot;)) {
                this.exceptionSorter = new InformixExceptionSorter();

            } else if (realDriverClassName.equals(&amp;quot;com.sybase.jdbc2.jdbc.SybDriver&amp;quot;)) {
                this.exceptionSorter = new SybaseExceptionSorter();

            } else if (realDriverClassName.equals(JdbcConstants.POSTGRESQL_DRIVER)
                    || realDriverClassName.equals(JdbcConstants.ENTERPRISEDB_DRIVER)) {
                this.exceptionSorter = new PGExceptionSorter();

            } else if (realDriverClassName.equals(&amp;quot;com.alibaba.druid.mock.MockDriver&amp;quot;)) {
                this.exceptionSorter = new MockExceptionSorter();
            } else if (realDriverClassName.contains(&amp;quot;DB2&amp;quot;)) {
                this.exceptionSorter = new DB2ExceptionSorter();

            } else {
                Class&amp;lt;?&amp;gt; superClass = driverClass.getSuperclass();
                if (superClass != null &amp;amp;&amp;amp; superClass != Object.class) {
                    driverClass = superClass;
                    continue;
                }
            }

            break;
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们使用的是org.apache.hive.jdbc.HiveDriver，算出来的ExceptionSort为空，那么这个补救的门也被关闭了，如果一直在使用，那么就只有一直的错下去&lt;/p&gt;

&lt;h2 id=&#34;bug修复方法&#34;&gt;bug修复方法&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;因为写一个ExceptionSort成本比较高，所以就在取的连接的时候，做一次连接可用性的检查，testOnBorrow设置为true&lt;/li&gt;
&lt;li&gt;validation_query  = &amp;ldquo;select 1&amp;rdquo;,对于普通的关系型数据库是一个比较好的选择，但对应hive就非常慢了,改成 &amp;ldquo;show databases&amp;rdquo; 就会快很多&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>HADOOP集群 健康状况检测方案</title>
      <link>https://hanzhihua.cn/post/sre_1/</link>
      <pubDate>Tue, 10 Sep 2019 11:09:03 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/sre_1/</guid>
      
        <description>

&lt;h2 id=&#34;hadoop集群-健康状况检测方案&#34;&gt;HADOOP集群 健康状况检测方案&lt;/h2&gt;

&lt;p&gt;流程：对linux的日志进行监控，当发生错误时候，对硬盘或者机器做下线处理&lt;/p&gt;

&lt;h3 id=&#34;监控方法&#34;&gt;监控方法&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;文件:/var/log/syslog  ,内容: &amp;ldquo;NIC Link is Down&amp;rdquo;,直接下线该机器&lt;/li&gt;
&lt;li&gt;文件::/var/log/syslog ,内容: &amp;ldquo;I/O error&amp;rdquo; 下线该磁盘&lt;/li&gt;
&lt;li&gt;文件::/var/log/syslog ,内容: &amp;ldquo;blk_update_request: critical medium error&amp;rdquo; 下线该磁盘&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>一个DAG系统的故障</title>
      <link>https://hanzhihua.cn/post/cs_2/</link>
      <pubDate>Thu, 05 Sep 2019 14:06:22 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/cs_2/</guid>
      
        <description>

&lt;p&gt;昨天线上DAG系统一个工作节点出现了OOM。
线上处理问题流程：&lt;strong&gt;先止损，后定位&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;现象重放&#34;&gt;现象重放&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;收到DAG系统一个工作节点的OOM告警&lt;/li&gt;
&lt;li&gt;查看DAG系统工作状态，发现DAG系统的调度任务工作正常&lt;/li&gt;
&lt;li&gt;查看监控系统，系统层面正常，该节点已经重启&lt;/li&gt;
&lt;li&gt;通过查看该节点的日志，没有发现特别的地方&lt;/li&gt;
&lt;li&gt;查找JVM crash的日志，但没有找到&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;问题分析-节点oom原因&#34;&gt;问题分析（节点OOM原因）&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;通过监控系统，发现该节点接受的工作请求与其他工作节点没有什么区别，而且crash 节点日志没有特别的地方。
多个工作节点，但只有一个工作节点出现了OOM，感觉是由于任务造成的&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;该节点重启时，并没有dump出内存快照?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;该节点重启是由于OOM而退出，supervisor又把它拉起来&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;进程启动脚本（部分）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;-XX:+UseG1GC -XX:ParallelGCThreads=24 
-XX:ConcGCThreads=16 -XX:InitiatingHeapOccupancyPercent=45 
-XX:NewRatio=2 -XX:SurvivorRatio=4 -XX:MaxTenuringThreshold=15 
-XX:-UseAdaptiveSizePolicy -Xms16G -Xmx16G -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/data/log/目录/应用_%p.hprof 
-XX:+PrintGCDetails -Xloggc:/data/log/目录/应用.log -XX:+PrintGCTimeStamps 
-Djava.security.egd=file:/dev/./urandom -Dfile.encoding=utf-8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主要的原因，TMD的 &lt;strong&gt;目录/data/log/目录&lt;/strong&gt; 不存在，下面是supervisor日志&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Java HotSpot(TM) 64-Bit Server VM warning: Cannot open file /data/log/目录/... due to No such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;哎，最宝贵的crash的内存快照、异常信息就没有了
留给我们的，只有痛苦的梳理crash节点当时运行过的每个任务了，静态的分析是否可能存在内存泄露情况&lt;/p&gt;

&lt;h2 id=&#34;改善措施&#34;&gt;改善措施&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;建立/data/log/目录/，（目录要建的，不然就是&amp;rsquo;带病&amp;rsquo;工作）&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>DATAX的玩法</title>
      <link>https://hanzhihua.cn/post/etl_1/</link>
      <pubDate>Sun, 01 Sep 2019 22:56:50 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/etl_1/</guid>
      
        <description>

&lt;p&gt;DATAX是阿里开源的一个优秀的ETL工具，使用框架+PLUGIN设计方式，通过依赖ClassLoader来隔离容错，总体设计还不错，被很多公司的数据团队使用&lt;/p&gt;

&lt;p&gt;做一个完整的数据平台的ETL工具，完全依靠DATAX也是不够，它只能算是一个引擎,一个基础,需要做二次开发&lt;/p&gt;

&lt;h2 id=&#34;二次开发功能点&#34;&gt;二次开发功能点&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;ETL主要是被DAG系统使用，所以数据的输入、描述是有DAG系统或者由统一的元信息服务来承担&lt;/li&gt;
&lt;li&gt;ETL需要被DAG的调度管理，一般都是依赖任务&lt;/li&gt;
&lt;li&gt;DAG系统承担着ETL任务引擎集群管理工作，包括路由、容错、服务发现等&lt;/li&gt;
&lt;li&gt;ETL引擎需要提供接口来接受DAG系统的指令，同时还需要上报任务状态、健康状态等工作&lt;/li&gt;
&lt;li&gt;多进程多节点的任务类型没有开源，需要自己实现&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>状态设计一点想法</title>
      <link>https://hanzhihua.cn/post/state_1/</link>
      <pubDate>Sat, 31 Aug 2019 22:56:31 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/state_1/</guid>
      
        <description>

&lt;p&gt;最近看到同事写的一段关于状态设计的代码（DAG项目，用java语言开发）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;ERROR(-1, &amp;quot;说明...&amp;quot;),
INIT(0, &amp;quot;说明...&amp;quot;),
SUCCESS(1, &amp;quot;说明...&amp;quot;),
FAILED(2, &amp;quot;说明...&amp;quot;),
RUNNING(3, &amp;quot;说明...&amp;quot;),
ON_QUEUE(4, &amp;quot;说明...&amp;quot;),
WAIT(6, &amp;quot;说明...&amp;quot;),
STOP(5, &amp;quot;说明...&amp;quot;),
ON_SUBMIT(7, &amp;quot;说明...&amp;quot;),,
WITH_RESULT(9, &amp;quot;说明...&amp;quot;),
FINISH(8, &amp;quot;说明...&amp;quot;),
DISPATCHED(10, &amp;quot;说明...&amp;quot;),

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;个人觉得有点问题，请各位看官分析&lt;/p&gt;

&lt;h2 id=&#34;有几个问题&#34;&gt;有几个问题&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;设计了一些不存在的状态，如finish状态，没有这个状态，结束态可以是成功、失败（里面包括人工kill掉），由方法来判断&lt;/li&gt;
&lt;li&gt;缺失了一些中间状态，如runing-&amp;gt;stop,缺失stoping状态&lt;/li&gt;
&lt;li&gt;stop状态换成killed状态语义更确切&lt;/li&gt;
&lt;li&gt;状态enum的value，设计混乱，没有业务语义&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Supervisor的正确玩法</title>
      <link>https://hanzhihua.cn/post/supervisor_1/</link>
      <pubDate>Tue, 27 Aug 2019 19:55:20 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/supervisor_1/</guid>
      
        <description>

&lt;p&gt;上次进程被莫名杀掉，为了避免同样错误的发生，现在我们统一接入supervisor，通过它来管理进程的启停&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;supervisor玩法有正确的玩法，也不正确的玩法（只有痛过才能真正体会）&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;不正确的玩法&#34;&gt;不正确的玩法&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;应用owner提供启动脚本（停止脚本一般是标配如kill -2 pid）&lt;/li&gt;
&lt;li&gt;运维同学安装supervisor,标准化目录结构&lt;/li&gt;
&lt;li&gt;运维同学提供supervisor配置文件&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;正确的玩法&#34;&gt;正确的玩法&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;应用owner提供启动脚本&lt;/li&gt;
&lt;li&gt;运维同学安装supervisor,标准化目录结构&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;应用owner提供supervisor配置文件&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;启动脚本例子&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
cp supervisor配置 /etc/supervisor/conf.d/
supervisorctl update
supervisorctl start 应用名
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;上面的脚本也可以写在发布系统中&lt;/li&gt;
&lt;li&gt;还有一种玩法就是发布系统只是负责应用的发布，不负责应用的启停，看官可以自选&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>采用snaphost版本</title>
      <link>https://hanzhihua.cn/post/mvn_1/</link>
      <pubDate>Mon, 26 Aug 2019 20:57:22 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/mvn_1/</guid>
      
        <description>

&lt;p&gt;因为是大数据部门，我们的应用基本上使用java语言开发，采用maven做项目管理&lt;br /&gt;
目前我们的项目版本都是snaphost的，线上发布也是这样的&lt;br /&gt;
本来想做一次整改，采用在线应用标准来要求，但发现效果并不好，会增加比较多的工作量&lt;br /&gt;
因为公司与之配套的工具平台缺失，公司项目主要以golang为主，对java支持的比较弱&lt;/p&gt;

&lt;h2 id=&#34;考虑数据平台项目的特点-我们内部达成一个共识&#34;&gt;考虑数据平台项目的特点，我们内部达成一个共识：&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;只使用snapshot版本，放弃release版本&lt;/li&gt;
&lt;li&gt;小功能开发，迭代不修改项目版本&lt;/li&gt;
&lt;li&gt;大功能修改或者对外接口变化才修改项目版本，仍采用snaphost版本&lt;/li&gt;
&lt;li&gt;版本回滚，依赖发布系统&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Nginx多次转发问题</title>
      <link>https://hanzhihua.cn/post/proxy_1/</link>
      <pubDate>Sat, 24 Aug 2019 18:49:06 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/proxy_1/</guid>
      
        <description>

&lt;p&gt;今天遇到一个nginx多次转发丢失客户端ip问题，原来的配置是这样的&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;proxy_set_header        X-Real-IP $remote_addr;
proxy_set_header        X-Forwarded-For $remote_addr;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;每一层nginx配置都是这样的，最后应用取得的客户端IP是上一层nginx的IP&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;根因是nginx的X-Real-IP被覆盖了&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;一般玩法&#34;&gt;一般玩法&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;可定义一个私有的变量 如 &lt;em&gt;x-backend-公司名-real-ip&lt;/em&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;第一层nginx&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;proxy_set_header        x-backend-公司名-real-ip $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;后面几层&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;应用方&lt;br /&gt;
通过x-backend-公司名-real-ip拿到客户端ip&lt;br /&gt;
通过X-Forwarded-For获得ip列表，(包括客户端IP、所有nginx的ip,通过逗号分隔，第一个为客户端IP）&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Mysql Exporter代码分析</title>
      <link>https://hanzhihua.cn/post/prom_1/</link>
      <pubDate>Sat, 24 Aug 2019 16:44:39 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/prom_1/</guid>
      
        <description>

&lt;p&gt;今天闲来无事看看 promthues的&lt;a href=&#34;https://github.com/prometheus/mysqld_exporter&#34;&gt;mysqlexporter&lt;/a&gt;
监控组件是如何实现的&lt;/p&gt;

&lt;h2 id=&#34;实现原理&#34;&gt;实现原理&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;遵循promethues的规范，提供http接口，返回标准的结果集&lt;/li&gt;

&lt;li&gt;&lt;p&gt;主要&lt;strong&gt;运行mysql命令采集指标&lt;/strong&gt;，包括以下指标，false默认不采集&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;var scrapers = map[collector.Scraper]bool{
	collector.ScrapeGlobalStatus{}:                        true,
	collector.ScrapeGlobalVariables{}:                     true,
	collector.ScrapeSlaveStatus{}:                         true,
	collector.ScrapeProcesslist{}:                         false,
	collector.ScrapeUser{}:                                false,
	collector.ScrapeTableSchema{}:                         false,
	collector.ScrapeInfoSchemaInnodbTablespaces{}:         false,
	collector.ScrapeInnodbMetrics{}:                       false,
	collector.ScrapeAutoIncrementColumns{}:                false,
	collector.ScrapeBinlogSize{}:                          false,
	collector.ScrapePerfTableIOWaits{}:                    false,
	collector.ScrapePerfIndexIOWaits{}:                    false,
	collector.ScrapePerfTableLockWaits{}:                  false,
	collector.ScrapePerfEventsStatements{}:                false,
	collector.ScrapePerfEventsStatementsSum{}:             false,
	collector.ScrapePerfEventsWaits{}:                     false,
	collector.ScrapePerfFileEvents{}:                      false,
	collector.ScrapePerfFileInstances{}:                   false,
	collector.ScrapePerfReplicationGroupMemberStats{}:     false,
	collector.ScrapePerfReplicationApplierStatsByWorker{}: false,
	collector.ScrapeUserStat{}:                            false,
	collector.ScrapeClientStat{}:                          false,
	collector.ScrapeTableStat{}:                           false,
	collector.ScrapeSchemaStat{}:                          false,
	collector.ScrapeInnodbCmp{}:                           true,
	collector.ScrapeInnodbCmpMem{}:                        true,
	collector.ScrapeQueryResponseTime{}:                   true,
	collector.ScrapeEngineTokudbStatus{}:                  false,
	collector.ScrapeEngineInnodbStatus{}:                  false,
	collector.ScrapeHeartbeat{}:                           false,
	collector.ScrapeSlaveHosts{}:                          false,
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;比如ScrapeGlobalStatus，就是运行 &lt;code&gt;SHOW GLOBAL STATUS&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>写文件性能总结</title>
      <link>https://hanzhihua.cn/post/io_1/</link>
      <pubDate>Sat, 24 Aug 2019 10:56:11 +0800</pubDate>
      
      <guid>https://hanzhihua.cn/post/io_1/</guid>
      
        <description>

&lt;p&gt;最近在项目中，看到一个已经离职同事写的关于写日志服务的代码&lt;/p&gt;

&lt;h1 id=&#34;写性能提升&#34;&gt;写性能提升&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;使用缓存，必要的时候在落盘&lt;/li&gt;
&lt;li&gt;预先定义文件大小，在生成文件生成一个长度固定的空文件&lt;/li&gt;

&lt;li&gt;&lt;p&gt;使用zero copy,可以是sendfile或者mmap方式,下面是mmap的例子&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;FileChannel fileChannel = new RandomAccessFile(this.file, &amp;quot;rw&amp;quot;).getChannel();
MappedByteBuffer mappedByteBuffer = fileChannel.map(MapMode.READ_WRITE, 0, 文件大小);
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;pagecache-刷盘策略&#34;&gt;Pagecache 刷盘策略&lt;/h1&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;调用fsync等。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;脏页太多（相关参数：dirty_background_ratio与dirty_ratio）。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;脏页太久（相关参数：dirty_expire_centisecs）
rocketmq 配置&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo sysctl -w vm.dirty_background_ratio=50 //当脏页占用的内存百分比超过此值
sudo sysctl -w vm.dirty_ratio=50 //当脏页占用的内存百分比超过此值
sudo sysctl -w vm.dirty_writeback_centisecs=360000 //一个小时回写
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
  </channel>
</rss>
